[
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Data Browser.\n\nData Browser includes data exploration and basic analysis",
    "Context_id": "4장_v3_sanitized::chunk_0001",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "Data Browser"
    ],
    "Section_length": 2,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Node using Data Browser.\n\nData Browser can be used in the following Input/Output Nodes:\n\n[Table:t9]",
    "Context_id": "4장_v3_sanitized::chunk_0002",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": true,
    "Table_ids": [
      "t9"
    ],
    "Section_path": [
      "Chapter 4 Data Browser",
      "Node using Data Browser"
    ],
    "Section_length": 2,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Getting started.\n\nAfter reading the data for each node, the Data Browser can be started using one of the three methods below.\n\nDouble click on the node\n\nSelect Data Browser from the right-click context menu\n\nClick [View] – [Data Browser] on the toolbar\n\nNOTE In the case of Display Node, it is automatically executed when the project is performed. To run the project directly, you can double-click the Display Node in the output window of the Resource window after executing the project.",
    "Context_id": "4장_v3_sanitized::chunk_0003",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "Getting started"
    ],
    "Section_length": 2,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Screen Layout.\n\nThe Data Browser interface is as follows.\n[image:rId7]\n\n[Image:rId7] The image shows the ECMiner software interface, specifically focusing on the \"File Reader\" node for loading data into a project. The data consists of time series measurements labeled A, B, C, and GROUP, with timestamps ranging from 2013-03-06 to 2013",
    "Context_id": "4장_v3_sanitized::chunk_0004",
    "Is_image": true,
    "Image_ids": [
      "rId7"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "Screen Layout"
    ],
    "Section_length": 2,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to UI.",
    "Context_id": "4장_v3_sanitized::chunk_0005",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.1 UI"
    ],
    "Section_length": 2,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to UI, focusing on Data Browser Screen Layout.\n\nThe layout in Data Browser is as follows.\n[image:rId8]\n\n[Image:rId8] The image shows an ECMiner data mining software interface with a dataset containing time series data across five variables labeled A, B, C, and GROUP, along with a TIME column. The main purpose is to analyze and visualize the data for descriptive statistics and variance analysis.",
    "Context_id": "4장_v3_sanitized::chunk_0006",
    "Is_image": true,
    "Image_ids": [
      "rId8"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.1 UI",
      "4.1.1 Data Browser Screen Layout"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to UI, under the subsection Data Browser Screen Layout, with a detailed reference to Windows Description.\n\n[Table:t30]",
    "Context_id": "4장_v3_sanitized::chunk_0007",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": true,
    "Table_ids": [
      "t30"
    ],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.1 UI",
      "4.1.1 Data Browser Screen Layout",
      "Windows Description"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to UI, focusing on Main Menu.",
    "Context_id": "4장_v3_sanitized::chunk_0008",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.1 UI",
      "4.1.2 Main Menu"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to UI, under the subsection Main Menu, with a detailed reference to Menu.\n\n[Table:t35]",
    "Context_id": "4장_v3_sanitized::chunk_0009",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": true,
    "Table_ids": [
      "t35"
    ],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.1 UI",
      "4.1.2 Main Menu",
      "Menu"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to UI, focusing on Sub-menu (using mouse and keyboard).\n\nThe submenu in the Data Browser pops up right-clicking.",
    "Context_id": "4장_v3_sanitized::chunk_0010",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.1 UI",
      "4.1.3 Sub-menu (using mouse and keyboard)"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to UI, under the subsection Sub-menu (using mouse and keyboard), with a detailed reference to Delete Column.\n\nHow to run: Right-click on the column number or field name in the data area column header, and a menu will be shown.\nResult: The selected column will be deleted from the data browser. After executing 'Apply' following the column deletion, a filter node will be added to the stream, removing the selected column.",
    "Context_id": "4장_v3_sanitized::chunk_0011",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.1 UI",
      "4.1.3 Sub-menu (using mouse and keyboard)",
      "Delete Column"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to UI, under the subsection Sub-menu (using mouse and keyboard), with a detailed reference to Delete Row.\n\nHow to run: Right-click on the row number in the row header of the data area and a menu will be shown.\nResult: The selected row will be deleted from the data browser. After executing 'Apply' following the row deletion, a Row Select Node will be added to the stream, removing the selected row",
    "Context_id": "4장_v3_sanitized::chunk_0012",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.1 UI",
      "4.1.3 Sub-menu (using mouse and keyboard)",
      "Delete Row"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to UI, under the subsection Sub-menu (using mouse and keyboard), with a detailed reference to Hide Column.\n\nHow to run: Right-click on the column number or field name in the data area column header and a menu will be shown.\nResult: The selected column will be hidden in the Data Browser.",
    "Context_id": "4장_v3_sanitized::chunk_0013",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.1 UI",
      "4.1.3 Sub-menu (using mouse and keyboard)",
      "Hide Column"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to UI, under the subsection Sub-menu (using mouse and keyboard), with a detailed reference to Cancel Hide Column.\n\nHow to run: Right-click on the column number or field name in the data area column header to show the hidden column number and field name. etc.\n[Copy] /[Copy with column names]/[Select all]/[Export Data to Excel] functions are additionally provided.",
    "Context_id": "4장_v3_sanitized::chunk_0014",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.1 UI",
      "4.1.3 Sub-menu (using mouse and keyboard)",
      "Cancel Hide Column"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to UI, focusing on Toolbar.\n\nToolbar in the Data Browser",
    "Context_id": "4장_v3_sanitized::chunk_0015",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.1 UI",
      "4.1.4 Toolbar"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to UI, under the subsection Toolbar, with a detailed reference to Toolbar Menu.\n\n[Table:t61]\n\n[Image:rId11] The image shows the ECMiner software interface, specifically the \"Data Mining\" tab. It displays a dataset with columns labeled \"A\", \"Z\", and an arrow indicating the direction of data flow. The main purpose is to analyze and mine data for patterns or insights.\n\n[Image:rId12] The image shows the ECMiner software interface, which is used for data mining and analysis. It displays various options and settings for configuring the mining process, including parameters like the number of threads, data sources, and output formats. The main purpose is to automate the extraction of patterns and insights from large datasets efficiently.\n\n[Image:rId13] The image shows a histogram in ECMiner, a data mining tool, displaying frequency distribution of data points. The x-axis represents different categories or variables, while the y-axis shows the count or frequency of occurrences for each category. This visualization helps in understanding the distribution and patterns within the dataset.\n\n[Image:rId14]\n\n[Image:rId15] The image shows the ECMiner software interface, which is used for data mining tasks. It displays various options like \"Data,\" \"Mining,\" and \"Settings,\" indicating that users can perform data analysis, mining operations, and configure settings for their mining projects. The presence of icons suggests functionalities such as loading datasets, running\n\n[Image:rId10] The image shows the ECMiner software interface, which is used for data mining tasks. It displays various options and settings for analyzing and processing datasets, including features like \"Data,\" \"Model,\" and \"Results.\" The main purpose is to facilitate the extraction of patterns and insights from large datasets through machine learning algorithms.\n\n[Image:rId9] The image shows the ECMiner software interface, which is used for data mining and analysis. It displays various options and settings for configuring the mining process, including parameters like the number of threads, data sources, and output formats. The main purpose is to automate the extraction of patterns and insights from large datasets efficiently.\n\n[Image:rId16] The image shows a data mining software interface with a focus on discrete dependent variables, likely for analyzing categorical data in machine learning tasks.",
    "Context_id": "4장_v3_sanitized::chunk_0016",
    "Is_image": true,
    "Image_ids": [
      "rId11",
      "rId12",
      "rId13",
      "rId14",
      "rId15",
      "rId10",
      "rId9",
      "rId16"
    ],
    "Is_table": true,
    "Table_ids": [
      "t61"
    ],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.1 UI",
      "4.1.4 Toolbar",
      "Toolbar Menu"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to UI, focusing on Data Area.\n\nYou can explore data and edit rows and columns in the original datasheet.",
    "Context_id": "4장_v3_sanitized::chunk_0017",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.1 UI",
      "4.1.5 Data Area"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to UI, under the subsection Data Area, with a detailed reference to Window Layout.\n\n[image:rId17]\n\n[Image:rId17] The image shows an Excel spreadsheet with data mining software, specifically ECMiner, analyzing correlation relationships between different variables. The columns represent various attributes like A1 to A8, while rows contain numerical values and labels such as B, M, G, etc., indicating different categories or types of data. The goal is to",
    "Context_id": "4장_v3_sanitized::chunk_0018",
    "Is_image": true,
    "Image_ids": [
      "rId17"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.1 UI",
      "4.1.5 Data Area",
      "Window Layout"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to UI, under the subsection Data Area, with a detailed reference to Window Description.\n\n[Table:t71]",
    "Context_id": "4장_v3_sanitized::chunk_0019",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": true,
    "Table_ids": [
      "t71"
    ],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.1 UI",
      "4.1.5 Data Area",
      "Window Description"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to UI, focusing on Results.\n\nManage the results in the Data Browser by clicking [Window] - [Results] or the [image:rId18] icon on toolbar. The results are grouped by type into categories such as “Chart” and “Descriptive Statistics”.\n\n[Image:rId18] The image shows an Excel spreadsheet named \"manufacturing_defect_dataset\" with columns for production volume, production cost, supplier quality, delivery delay, defect rate, quality score, maintenance hours, downtime percentage, inventory turnover, and stockout rate. The data is used to analyze manufacturing defects in a dataset.",
    "Context_id": "4장_v3_sanitized::chunk_0020",
    "Is_image": true,
    "Image_ids": [
      "rId18"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.1 UI",
      "4.1.6 Results"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to UI, under the subsection Results, with a detailed reference to Window Layout.\n\n[image:rId19]\n\n[Image:rId19] The image shows an interface for analyzing a manufacturing defect dataset in ECMiner, focusing on descriptive statistics and quality metrics like production volume, cost, supplier quality, delivery delay, and defect rate.",
    "Context_id": "4장_v3_sanitized::chunk_0021",
    "Is_image": true,
    "Image_ids": [
      "rId19"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.1 UI",
      "4.1.6 Results",
      "Window Layout"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to UI, under the subsection Results, with a detailed reference to Results Toolbar Menu.\n\n[Table:t80]\n\n[Image:rId21] The image shows the ECMiner software interface, which is used for data mining and analysis. It displays various options and settings for configuring the mining process, including parameters like the number of threads, data sources, and output formats. The main purpose is to automate the extraction of patterns and insights from large datasets efficiently.\n\n[Image:rId22] The image shows the ECMiner software interface, specifically the \"Data Mining\" tab. It displays various options for data analysis, including \"Load Data,\" \"Run Analysis,\" and \"Save Results.\" The main purpose is to facilitate data mining tasks by providing tools for loading datasets, running algorithms, and saving outcomes.\n\n[Image:rId23] The image shows the ECMiner software interface, specifically the \"Data Mining\" tab. It displays various options for data analysis, including \"Load Data,\" \"Run Analysis,\" and \"Save Results.\" The highlighted element is likely related to selecting or managing datasets for mining operations.\n\n[Image:rId24] The image shows the ECMiner software interface, which is used for data mining and analysis. It displays various options and settings for configuring the mining process, including parameters like time, frequency, and algorithm selection. The main purpose is to help users extract valuable insights from large datasets efficiently.\n\n[Image:rId25] The image shows the ECMiner software interface, which is used for data mining and analysis. It displays various options and settings for configuring the mining process, including parameters like the number of threads, data sources, and output formats. The main purpose is to automate the extraction of patterns and insights from large datasets efficiently.\n\n[Image:rId20] The image shows the ECMiner software interface, which is used for data mining and analysis. It displays various options and settings for configuring the mining process, including parameters like the number of threads, data sources, and output formats. The main purpose is to automate the extraction of patterns and insights from large datasets efficiently.",
    "Context_id": "4장_v3_sanitized::chunk_0022",
    "Is_image": true,
    "Image_ids": [
      "rId21",
      "rId22",
      "rId23",
      "rId24",
      "rId25",
      "rId20"
    ],
    "Is_table": true,
    "Table_ids": [
      "t80"
    ],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.1 UI",
      "4.1.6 Results",
      "Results Toolbar Menu"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to File.",
    "Context_id": "4장_v3_sanitized::chunk_0023",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.2 File"
    ],
    "Section_length": 2,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to File, focusing on Reload.\n\nReloads the data from a file or DB.",
    "Context_id": "4장_v3_sanitized::chunk_0024",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.2 File",
      "4.2.1 Reload"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to File, under the subsection Reload, with a detailed reference to How to run.\n\n[File(F)] - [Reload(R)] in the menu.\n[image:rId26]\n\n[Image:rId26] The image shows a screenshot of the ECMiner data mining software, specifically focusing on the \"Analyze\" tab. The user is interacting with a dataset containing three columns labeled A1, A2, and A3, with corresponding values for rows 1 to 3. The main purpose appears to be analyzing or",
    "Context_id": "4장_v3_sanitized::chunk_0025",
    "Is_image": true,
    "Image_ids": [
      "rId26"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.2 File",
      "4.2.1 Reload",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to File, focusing on Save.\n\nSave the data.",
    "Context_id": "4장_v3_sanitized::chunk_0026",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.2 File",
      "4.2.2 Save"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to File, under the subsection Save, with a detailed reference to How to run.\n\n[File(F)] - [Save(S)] in the menu or the [image:rId27] icon on the toolbar.\n[image:rId28]\n\n[Image:rId27] The image shows the ECMiner software interface, which is used for data mining and analysis. It displays various options and settings for configuring the mining process, including parameters like the number of threads, data sources, and output formats. The main purpose is to automate the extraction of patterns and insights from large datasets efficiently.\n\n[Image:rId28] The image shows the \"Save\" option in the File menu of ECMiner, which is used to save the current analysis results as a file. The content includes numerical data in columns A1, A2, and A3, with corresponding letters B and M in columns B and C, respectively. This suggests that",
    "Context_id": "4장_v3_sanitized::chunk_0027",
    "Is_image": true,
    "Image_ids": [
      "rId27",
      "rId28"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.2 File",
      "4.2.2 Save",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to File, under the subsection Save, with a detailed reference to Save file.\n\nFiles can be saved with extensions such as \"txt\", \"csv\", and “ ecl \".",
    "Context_id": "4장_v3_sanitized::chunk_0028",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.2 File",
      "4.2.2 Save",
      "Save file"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze.",
    "Context_id": "4장_v3_sanitized::chunk_0029",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze"
    ],
    "Section_length": 2,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, focusing on Data Summary Statistics.\n\n(1) All Data\n\nData Summary Statistics – All Data displays summary statistics of all the variables.\n\nHow to run\n\n[Analyze] – [Data Summary Statistics] – [All Data]\n\n[image:rId29]\n\n[Image:rId29] The image shows a table from ECMiner, a data mining software, with columns labeled A1 to A9 and a column for customer churn status. The table contains numerical data and categorical variables, likely used for analyzing customer behavior and churn prediction.\n\nResults\n\n[image:rId30]\n\n[Image:rId30] The image shows a data distribution analysis in ECMiner, displaying basic statistics for continuous variables TIME, A, B, and C, along with a discrete variable GROUP. The data includes counts, frequencies, percentages, averages, minimums, maximums, and ranges for each variable.",
    "Context_id": "4장_v3_sanitized::chunk_0030",
    "Is_image": true,
    "Image_ids": [
      "rId29",
      "rId30"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.1 Data Summary Statistics"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Data Summary Statistics, with a detailed reference to (2) Continuous Data.\n\nData Summary Statistics – Continuous Data shows descriptive statistics with box plot for all continuous data.\n\nHow to run\n\n[Analyze] – [Data Summary Statistics] – [Continuous Data]\n\nResults\n\n[image:rId31]\n\n[Image:rId31] The image shows the File Reader window in ECMiner, displaying statistical information about continuous variables in a dataset. It includes details like variable names, types, counts, total values, averages, minimums, maximums, ranges, and box plots for each variable. The main purpose is to analyze and visualize the distribution of\n\nOutput Statistics\n\nTotal, Average, Box plot, Number of Missing Values, Minimum Value, Maximum Value, Range, Variance, Standard Deviation, Kurtosis, Skewness, Median, and Quartile are supported.\n\nNOTE The numbers at either end of the box plot indicates the number of outliers. If the number of outliers exceeds 100, it is displayed as '*'.",
    "Context_id": "4장_v3_sanitized::chunk_0031",
    "Is_image": true,
    "Image_ids": [
      "rId31"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.1 Data Summary Statistics",
      "(2) Continuous Data"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Data Summary Statistics, with a detailed reference to (3) Discrete Data.\n\nData Summary Statistics – Discrete Data shows descriptive statistics for discrete data.\n\nHow to run\n\n[Analyze] – [Data Summary Statistics] – [Discrete Data]\n\nResults\n\n[image:rId32]\n\n[Image:rId32]\n\nOutput Statistics\n\nNumber of Missing Values, Variable Values, Frequency, Cumulative Frequency, Percentage, Valid Percentage, and Cumulative Percentage.",
    "Context_id": "4장_v3_sanitized::chunk_0032",
    "Is_image": true,
    "Image_ids": [
      "rId32"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.1 Data Summary Statistics",
      "(3) Discrete Data"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, focusing on Basic Statistics.",
    "Context_id": "4장_v3_sanitized::chunk_0033",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.2 Basic Statistics"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Basic Statistics, with a detailed reference to Descriptive Statistics.\n\nBasic Statistics – Descriptive Statistics shows descriptive statistics of the selected variables.",
    "Context_id": "4장_v3_sanitized::chunk_0034",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.2 Basic Statistics",
      "4.3.2.1 Descriptive Statistics"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Basic Statistics, with a detailed reference to How to run.\n\n[Analyze] – [Basic Statistics] – [Descriptive Statistics]",
    "Context_id": "4장_v3_sanitized::chunk_0035",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.2 Basic Statistics",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Basic Statistics, with a detailed reference to Descriptive Statistics options.\n\n[image:rId33]\n\n[Image:rId33] The image shows the \"Descriptive Statistics\" window in ECMiner, a data mining software tool. It allows users to calculate various statistical measures such as sum, mean, median, variance, standard deviation, minimum, maximum, range, geometric mean, harmonic mean, quartile, and interquartile range for\n\nAdd a variable or remove a variable using Add and Delete button.\n\nSelect the variable for the descriptive statistics.\n\nButton is another way to select the column header in the data browser\n\nClick the boxes to select or deselect the statistics.",
    "Context_id": "4장_v3_sanitized::chunk_0036",
    "Is_image": true,
    "Image_ids": [
      "rId33"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.2 Basic Statistics",
      "Descriptive Statistics options"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Basic Statistics, with a detailed reference to Results.\n\n[image:rId34]\n\n[Image:rId34] The image displays statistical summary statistics for a dataset, including mean, minimum, maximum, range, variance, standard deviation, kurtosis, skewness, median, and quartiles Q1, Q2, and Q3. These metrics provide insights into the distribution and characteristics of the data.",
    "Context_id": "4장_v3_sanitized::chunk_0037",
    "Is_image": true,
    "Image_ids": [
      "rId34"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.2 Basic Statistics",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Basic Statistics, with a detailed reference to Output Statistics.\n\nThe chosen statistics are shown. For all of the statistics, Sum, Mea n, Median, Variance, Standard Deviation, Minimum, Maximum, Range, Geamean, Harmmean, Quartile, Iqr, Mode, Skewness, Kurtosis, Css, Rms, Uss, Avedev, Devsq, Tabulate, Midrange, and Cv are supported.",
    "Context_id": "4장_v3_sanitized::chunk_0038",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.2 Basic Statistics",
      "Output Statistics"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Basic Statistics, with a detailed reference to Correlation Analysis.\n\n(1) Display on Screen\n\nCorrelation Analysis – Display on Screen shows the correlation.\n\nHow to run\n\n[Analyze] – [Basic Statistics] – [Correlation Analysis] – [Display on Screen]\n\nResults\n\n[image:rId35]\n\n[Image:rId35] The image shows the Correlation Relationship tab in ECMiner, displaying correlation coefficients between different variables (A1 to A8) and a churn status variable. The goal is to identify relationships and patterns among these variables for data analysis and decision-making.\n\nOutput Statistics\n\nCor (correlation value), and p (p-value)\n\nCorrelation chart\n\nDistribution chart with a trend line is displayed double-clicking the selected correlation table.\n\n[image:rId36]\n\n[Image:rId36] The image shows a correlation chart comparing A5 and A8, with a linear regression line indicating a strong positive correlation (r = 0.880156) between the two variables. The equation y = 5.900829x - 48.4410\n\n(2) Save to File\n\nCorrelation Analysis – Save to File do save the correlation table as text file.\n\nHow to run\n\n[Analyze] – [Basic Statistics] – [Correlation Analysis] – [Save on File]. Specify the file name, directory, and the correlation coefficient value. Results are stored only for variables that have correlation the specified value. ≥\n\n[image:rId37]\n\n[Image:rId37] The image is a save dialog box for saving correlation analysis results in ECMiner, with a filename \"Correlation_Data.txt\" and a correlation coefficient of 0.3. Only variables with correlation coefficients greater than or equal to 0.3 will be saved. The user can choose to save all values by entering\n\nResults\n\n[image:rId38]\n\n[Image:rId38] The image shows a correlation matrix in ECMiner, displaying the relationships between variables A5, A7, and A8. The values indicate strong positive correlations among these variables.\n\n(3) Correlation Wheel\n\nCorrelation Analysis – Correlation Wheel shows the correlation between variables using the color and thickness of the connecting lines.\n\nHow to run\n\n[Analyze] – [Basic Statistics] – [Correlation Analysis] – [Correlation Wheel]\n\nResults\n\n[Table:t197]\n\n[Image:rId39] The Correlation Visualizer in ECMiner displays a scatter plot with points labeled A1, A2, A3, A4, and A7, showing correlations between variables within a selected interval of 1 to 8530. The red line indicates a strong positive correlation between these points.\n\nRed means positive correlation, blue means negative correlation, and the thicker the connecting line, the larger the absolute value of the correlation coefficient. On the top right corner, there is a menu to adjust the coefficient threshold value, line thickness, and tension. The coefficient threshold allows you to selectively view the meaningful correlation between variables.",
    "Context_id": "4장_v3_sanitized::chunk_0039",
    "Is_image": true,
    "Image_ids": [
      "rId35",
      "rId36",
      "rId37",
      "rId38",
      "rId39"
    ],
    "Is_table": true,
    "Table_ids": [
      "t197"
    ],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.2 Basic Statistics",
      "4.3.2.2 Correlation Analysis"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Basic Statistics, with a detailed reference to Mean Comparison Analysis.\n\n(1) One-Sample t-test\n\nOne-sample t-test is to test whether the mean of one sample differs significantly from the specified mean.\n\nHow to run\n\n[Analyze] -[Basic Statics]–[Mean Comparison Analysis] ]-[One Sample t-Test]\n\n[Table:t208]\n\n[Image:rId40] The image shows the One Sample t-Test dialog in ECMiner, used to test if the mean of variable A1 is significantly different from zero at a significance level of 0.05.\n\nResult\n\nOne-sample t-test statistics result.\n\n[image:rId41]\n\n[Image:rId41] The image shows a One-Sample t-Test conducted in ECMiner, analyzing variable A1 with 7,596 data points. The test indicates that the mean of A1 is significantly different from zero at p = 0.00000, suggesting a strong statistical significance.\n\n(2) Two Sample t-Test\n\nTwo Sample t-Test is to compare the average of two independent samples.\n\nHow to run\n\n[Analyze] -[Basic Statics]–[Mean Comparison Analysis]-[Two Sample t-Test]\n\n[Table:t219]\n\n[Image:rId42] The image shows an interface for conducting a Two Sample t-Test in ECMiner, where users can select variables to compare, specify a group variable, and set significance levels for statistical analysis.\n\nResult\n\nTwo-sample t-test statistics result.\n\n[image:rId43]\n\n[Image:rId43] The image shows a Two Sample t-Test conducted in ECMiner, comparing two groups labeled A1 and A2. Group A1 has 3846 data points with an average of 28.67447 and a standard deviation of 12.59226,\n\n(3) Paired Samples\n\nPaired t-test is to test whether the mean difference between two paired observations. Measurements are taken on the same subjects before and after a treatment, or paired observatio n\n\nHow to run\n\n[Analyze] -[Basic Statics]–[Mean Comparison Analysis]-[Paired t-Test]\n\n[Table:t230]\n\n[Image:rId44] The image shows the Paired t-Test window in ECMiner, used to compare two related groups (A1 and A5) for statistical significance at a chosen significance level (0.05).\n\nResult\n\nPaired t-Test results.\n\n[image:rId45]\n\n[Image:rId45] The T-Test (Paired Sample) screen in ECMiner shows paired sample statistics for A1 and A5, with averages of 30.42204 and 177.83057 respectively, standard deviations of 12.80825 and",
    "Context_id": "4장_v3_sanitized::chunk_0040",
    "Is_image": true,
    "Image_ids": [
      "rId40",
      "rId41",
      "rId42",
      "rId43",
      "rId44",
      "rId45"
    ],
    "Is_table": true,
    "Table_ids": [
      "t208",
      "t219",
      "t230"
    ],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.2 Basic Statistics",
      "4.3.2.3 Mean Comparison Analysis"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Basic Statistics, with a detailed reference to Proportion Test.\n\n(1) One sample Proportion Test\n\nOne sample proportion test of the specified ratio with confidence interval.\n\nHow to run\n\n[Analyze] - [Basic Statistics] - [Proportion Test] - [One sample Proportion Test]\n\n[image:rId46]\n\n[Image:rId46] The image shows a One Sample Poisson Test setup in ECMiner, where the user is selecting to test if the population proportion of \"chum_status\" variable is greater than 0.5 at a significance level of 0.05.\n\n-Select a variable. Choose event class among the class of variable.\n\n-Set hypothesis parameter\n\n-Set confidence interval.\n\nResults\n\nThe smaller a P-value is, the greater the possibility of rejecting a null hypothesis is.\n\n[image:rId47]\n\n[Image:rId47] The image shows a One Sample Proportion Test conducted in ECMiner, testing whether the population proportion is greater than 0.5. The test has 8,530 observations with 4,684 events, resulting in a sample ratio of 0.54912. The z\n\n(2) Two sample Proportion Test\n\nTwo sample proportion test is to test significant difference between two groups.\n\nHow to run\n\n[Analyze] - [Basic Statistics] - [Proportion Test] - [Two Sample Proportion Test]\n\n[image:rId48]\n\n[Image:rId48] The image shows the settings for a Two Sample Proportion Test in ECMiner, comparing churn status between two groups. The user has selected \"churn_status\" as both Variable 1 and Variable 2, with a significance level set to 0.05, indicating a preference for a 95%\n\n-Select variables. Choose event class among the class of variable.\n\n-Set hypothesis parameter.\n\n-Set confidence level\n\nResults\n\nThe smaller a P-value is, the greater the possibility of rejecting a null hypothesis is. Therefore, the proportion difference between two populations can be claimed like the type of an alternative hypothesis.\n\n[image:rId49]\n\n[Image:rId49] The image shows results from a Two Proportion Test using ECMiner, comparing two variables A2 and A9. The null hypothesis is that there's no difference in population proportions between the two variables, while the alternative hypothesis suggests that A9 has a higher proportion than A2. Both variables have similar sample sizes and\n\n(3) One-Sample Poisson Test\n\nTests whether the event rate in a sample follows a Poisson distribution and matches the expected value.\n\nHow to run\n\n[Analyze] - [Basic Statistics] – [Proportion Test] – [One Sample Poisson Test]\n\n[image:rId50]\n\n[Image:rId50] The image shows a One Sample Proportion Test setup in ECMiner, where the user is analyzing variable A1 with an event class of 1, testing whether the population proportion differs from 28 at a significance level of 0.05.\n\n-The following procedures are performed after a desired method is chosen between variable selection method and manual input method.\n\n-The variable selection method uses an integer variable and selects a corresponding variable and decides the length of an observation value.\n\n-In the manual input method, the number of a trial and the number of an event occurrence is entered directly.\n\n-For verification the population ratio is set in a null hypothesis, and the type and significance level of an alternative hypothesis is selected.\n\nResults\n\nThe test results of a chosen method are presented in a table as follows; The smaller a P-value is, the greater the possibility of rejecting a null hypothesis is. Therefore, the population proportion can be claimed like the type of an alternative hypothesis.\n\n[image:rId51]\n\n[Image:rId51] The One Sample Poisson Test screen in ECMiner shows hypothesis testing results for variable A1, with a null hypothesis of Population Proportion = 28.000000 and an alternative hypothesis that it is not the same. The test indicates a high z-value (42.274\n\n(4) Two Sample Poisson Test\n\nTests whether the event rates of two independent samples, assumed to follow Poisson distributions, are significantly different.\n\nHow to run\n\n[Analyze] - [Basic Statistics] – [Proportion Test] – [Two Sample Poisson Test],\n\n[image:rId52]\n\n[Image:rId52] The image shows the settings for a Two Sample Poisson Test in ECMiner, where Variable 1 is A1 and Variable 2 is A7 with one observation. The null hypothesis states a population proportion difference of 0.5, and the alternative hypothesis is that it's \"Bigger than.\" The significance\n\n-The following procedures are performed after a desired method is chosen between variable selection method and manual input method.\n\n-The variable selection method uses an integer variable and selects corresponding two variables and decides the length of an observation value.\n\n-In the manual input method, the number of two trials and the number of an event occurrence is entered directly.\n\n-For verification the population ratio is set in a null hypothesis, and the type and significance level of an alternative hypothesis is selected.\n\nResults\n\nThe test results of a chosen method are presented in a table as follows; The smaller a P-value is, the greater the possibility of rejecting a null hypothesis is. Therefore, the difference of the population proportion of 2-sample Poisson can be claimed like the type of an alternative hypothesis.\n\n[image:rId53]\n\n[Image:rId53] The Two Sample Poisson Test in ECMiner compares two groups (A1 and A7) to determine if there is a significant difference in their incidence rates, with a null hypothesis stating no difference and an alternative hypothesis suggesting a larger difference. The test shows that both groups have similar average occurrence counts and rate differences,",
    "Context_id": "4장_v3_sanitized::chunk_0041",
    "Is_image": true,
    "Image_ids": [
      "rId46",
      "rId47",
      "rId48",
      "rId49",
      "rId50",
      "rId51",
      "rId52",
      "rId53"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.2 Basic Statistics",
      "4.3.2.4 Proportion Test"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Basic Statistics, with a detailed reference to Variance Test.\n\n(1) One Sample Variance Test\n\nData explorer provides the function of single sample variance test that calculates the confidence interval and tests a hypothesis for the variance of a continuous variable.\n\nHow to run\n\n[Analyze] - [Basic Statistics] - [Variance Test] - [One Sample Variance Test]\n\n[image:rId54]\n\n[Image:rId54] The image shows an \"One Sample Variance Test\" dialog in ECMiner, where the user is conducting a statistical test on variable A1 to determine if its population variance differs significantly from a hypothesized value of 0.5 at a significance level of 0.05.\n\n-A target variable is chosen for single sample variance test.\n\n-For verification, the variance value of a population is set in a null hypothesis and the type and significance level of an alternative hypothesis is selected.\n\nResults\n\nThe test results of a chosen method are presented in a table as follows; The smaller a P-value is, the greater the possibility of rejecting a null hypothesis is. Therefore, the variance of a population can be claimed like the type of an alternative hypothesis\n\n[image:rId55]\n\n[Image:rId55] The image shows a Single Sample Variance Test in ECMiner, testing whether the population variance is equal to 5.000000 against the alternative hypothesis that it is not. The test has 8,530 observations with a standard deviation of 12,80825\n\n(2) Two Sample Variance Test\n\nData explorer provides the function of double sample variance test that calculates the confidence interval and tests a hypothesis for the ratio of the variance of two continuous variables.\n\nHow to run\n\n[Analyze] - [Basic Statistics] - [Variance Test] - [Two Sample Variance Test]\n\n[image:rId56]\n\n[Image:rId56] The image shows an interface for conducting a Two Sample Variance Test using ECMiner, where variables A1 and A5 are compared to test if their population variances are equal. The significance level is set at 0.05, indicating a 5% risk of rejecting the null hypothesis when it is true\n\n-Two variables are chosen for double sample variance test.\n\n-For verification, the variance ratio of a population is set in a null hypothesis and the type and significance level of an alternative hypothesis is selected.\n\nResults\n\nThe test results of a chosen method are presented in a table as follows; The smaller a P-value is, the greater the possibility of rejecting a null hypothesis is. Therefore, the ratio of the variance of two populations can be claimed like the type of an alternative hypothesis.\n\n[image:rId57]\n\n[Image:rId57] The image shows a Two Sample Variance Test in ECMiner, comparing two groups (A1 and A5) with 8530 observations each. The null hypothesis is that the population variance ratio equals 1, while the alternative hypothesis is that it's greater than 1. The test results indicate no",
    "Context_id": "4장_v3_sanitized::chunk_0042",
    "Is_image": true,
    "Image_ids": [
      "rId54",
      "rId55",
      "rId56",
      "rId57"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.2 Basic Statistics",
      "4.3.2.5 Variance Test"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Basic Statistics, with a detailed reference to Normality Test.\n\nNormality test is for testing whether data is normally distributed. It takes Anderson-Darling and Kolmogorov-Smirnov tests.",
    "Context_id": "4장_v3_sanitized::chunk_0043",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.2 Basic Statistics",
      "4.3.2.6 Normality Test"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Basic Statistics, with a detailed reference to How to run.\n\n[Analyze] – [Basic Statistics] - [Normality Test]\n[image:rId58]\nSelect a variable and choose the test method.\n\n[Image:rId58] The image shows the Normality Test window in ECMiner, where users can select variables for normality testing using either Anderson-Darling or Kolmogorov-Smirnov methods. The goal is to assess whether the selected continuous variables follow a normal distribution.",
    "Context_id": "4장_v3_sanitized::chunk_0044",
    "Is_image": true,
    "Image_ids": [
      "rId58"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.2 Basic Statistics",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Basic Statistics, with a detailed reference to Results.\n\nThe smaller a p-value is, the more normal distribution is not.\n[image:rId59]\n\n[Image:rId59] The image shows the results of a normality test for dataset A5 using two methods: Anderson-Darling and Kolmogorov-Smirnov. The test statistics and p-values indicate that the data is significantly non-normal, with both tests yielding very low p-values (0.000000\n\nNormal probability plot\n\nIt shows whether data follows a normal distribution. If the data points form a roughly straight line, it suggests that the data is normally distributed.\n\n[image:rId60]\n\n[Image:rId60] The image shows the Normality Distribution Results for variable A5 in ECMiner, displaying a Z-value distribution plot with a normal curve. The plot indicates that the data is normally distributed, as the points align closely with the theoretical normal distribution line.",
    "Context_id": "4장_v3_sanitized::chunk_0045",
    "Is_image": true,
    "Image_ids": [
      "rId59",
      "rId60"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.2 Basic Statistics",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Basic Statistics, with a detailed reference to Poisson Test.\n\nThe Poisson goodness-of-fit test is a technique that tests whether the collected data follows a Poisson distribution.",
    "Context_id": "4장_v3_sanitized::chunk_0046",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.2 Basic Statistics",
      "4.3.2.7 Poisson Test"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Basic Statistics, with a detailed reference to How to run.\n\n[Analyze] – [Basic Statistics] – [Poisson Test]\nSelect a variable. If you want to a distribution chart of observed and expected values, then select it.\n[image:rId61]\n\n[Image:rId61] The image shows the \"Poisson Distribution Goodness-of-Fit Test\" window in ECMiner, where users can select a continuous variable for analysis. The user has chosen \"A1\" as the variable to test against a Poisson distribution. The graph option is set to display both observed and expected values.",
    "Context_id": "4장_v3_sanitized::chunk_0047",
    "Is_image": true,
    "Image_ids": [
      "rId61"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.2 Basic Statistics",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Basic Statistics, with a detailed reference to Results.\n\nThe analysis results include the Poisson probability, an expected value, and chi-square test statistic for each variable.\n[image:rId62]\nIn the Poisson distribution tab of the results window, you can view the distribution chart of observed and expected values.\n[image:rId63]\n\n[Image:rId62] The Poisson Distribution Goodness-of-Fit Test in ECMiner assesses whether observed data fits a Poisson distribution, with results showing various categories' observations, estimated means, probabilities, expected values, and contributions to chi-square test statistic.\n\n[Image:rId63] The image shows a Poisson Distribution Goodness-of-Fit Test in ECMiner, comparing observed (red bars) and expected (green bars) values for various counts ranging from 13 to 51. The test evaluates whether the observed data fits a Poisson distribution, with higher counts showing better fit as",
    "Context_id": "4장_v3_sanitized::chunk_0048",
    "Is_image": true,
    "Image_ids": [
      "rId62",
      "rId63"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.2 Basic Statistics",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, focusing on Variance Analysis.",
    "Context_id": "4장_v3_sanitized::chunk_0049",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.3 Variance Analysis"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Variance Analysis, with a detailed reference to One-way ANOVA.\n\nOne-way ANOVA is a statistical method that involves one factor and is used to determine whether there are significant differences in the means of three or more independent groups.",
    "Context_id": "4장_v3_sanitized::chunk_0050",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.3 Variance Analysis",
      "4.3.3.1 One-way ANOVA"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Variance Analysis, with a detailed reference to How to run.\n\n[Analyze] - [Variance Analysis] - [One-way ANOVA]\n[image:rId64]\nFactor: Select one discrete variable which has different groups or categories.\nObserved Value: Select continuous variables that affect the group means.\n\n[Image:rId64]\n\n[Table:t370]\n\n[Image:rId65] The image is a post-hoc analysis window in ECMiner, used for statistical testing after ANOVA to compare group means. It allows users to choose between LSD, Tukey, Scheffe, and Duncan methods based on significance levels (0.05 or 0.01).",
    "Context_id": "4장_v3_sanitized::chunk_0051",
    "Is_image": true,
    "Image_ids": [
      "rId64",
      "rId65"
    ],
    "Is_table": true,
    "Table_ids": [
      "t370"
    ],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.3 Variance Analysis",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Variance Analysis, with a detailed reference to Result.\n\nResults can be saved to an HTML file by clicking the save icon located in the top-left corner of the window.\n\n[Table:t374]\n\n[Image:rId66] This screenshot shows an analysis of variance (ANOVA) table for a dataset with one factor, A2, and four groups. The LSD method is used to compare group means, indicating that within each group, the average levels are not significantly different.",
    "Context_id": "4장_v3_sanitized::chunk_0052",
    "Is_image": true,
    "Image_ids": [
      "rId66"
    ],
    "Is_table": true,
    "Table_ids": [
      "t374"
    ],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.3 Variance Analysis",
      "Result"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Variance Analysis, with a detailed reference to Two-way ANOVA.\n\nTwo-way ANOVA is a statistical method that involves two factors and interaction between the two factors. It is used to determine whether there are significant differences in the means of three or more independent groups.",
    "Context_id": "4장_v3_sanitized::chunk_0053",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.3 Variance Analysis",
      "4.3.3.2 Two-way ANOVA"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Variance Analysis, with a detailed reference to How to run.\n\n[Analyze] - [Variance Analysis] - [Two-way ANOVA]\n[image:rId67]\nFirst/Second Factor: Select two discrete variables that which has different groups or categories.\nObserved Value: Select continuous variables that affect the group means.\n\n[Image:rId67]",
    "Context_id": "4장_v3_sanitized::chunk_0054",
    "Is_image": true,
    "Image_ids": [
      "rId67"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.3 Variance Analysis",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Variance Analysis, with a detailed reference to Result.\n\nResults can be saved to an HTML file by clicking the save icon located in the top-left corner of the window.\n[image:rId68]\n\n[Image:rId68] The Two-Way ANOVA Table summarizes the results of an experiment comparing brightness (Factor A) and temperature (Factor B) on a response variable named \"result\". The table shows that temperature has a significant effect on the result, with an F-value of 15.72 and a P-value of",
    "Context_id": "4장_v3_sanitized::chunk_0055",
    "Is_image": true,
    "Image_ids": [
      "rId68"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.3 Variance Analysis",
      "Result"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Variance Analysis, with a detailed reference to GLM (General Linear Model).\n\nGeneral Linear Model can handle imbalanced data that often appears in real situations and can also handle covariates.",
    "Context_id": "4장_v3_sanitized::chunk_0056",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.3 Variance Analysis",
      "4.3.3.3 GLM (General Linear Model)"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Variance Analysis, with a detailed reference to How to run.\n\n[Analyze] – [Variance analysis] – [General Linear Model]\n[image:rId69]\nFactor Variables: Enter the variables corresponding to the factors used in the experiment. At this time, the selected continuous variable is automatically processed as a covariate.\nResponse Variables: Multiple selections are possible, and if multiple selections are made, you can obtain results for analysis of variance and linear regression models for multiple response variables.\nSelected Terms: Select interaction terms you may want.\nResidual Plot: Selected residual plots will be displayed on the results page.\nType of sum of Squares: Choose whether to use Modified or Sequential Sum of Square.\nType of Residuals: Choose whether to use Residuals, Standardized Residuals, or External Standardized Residuals.\n\n[Image:rId69] The image is a screenshot of the GLM (Generalized Linear Model) module in ECMiner, showing settings for factor variables, response variables, and selected terms. The user has chosen A1, A2, and A3 as factor variables, with A1A2 and A1A3 also selected.",
    "Context_id": "4장_v3_sanitized::chunk_0057",
    "Is_image": true,
    "Image_ids": [
      "rId69"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.3 Variance Analysis",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Variance Analysis, with a detailed reference to Result.\n\nGeneral Information shows the ANOVA Table, regression analysis results, and abnormal observation.\n[image:rId70]\n\n[Image:rId70] The image shows an ANOVA table for response value A6 in a General Linear Model using GLM in ECMiner. It evaluates factors A1, A2, and A3 with their interactions, providing SS, MS, F, and P values to assess significance. The R² and Adjusted R²\n\nNormal Probability Plot\n\nMore data points near the red line indicate that the residuals are closer to a normal distribution.\n\n[image:rId71]\n\n[Image:rId71] The image shows a GLM (Generalized Linear Model) analysis in ECMiner, displaying a normal probability plot with residuals plotted against fitted values. The plot indicates that the residuals are normally distributed, suggesting good model fit.\n\nResidual vs. Fitted Values Plot\n\nPlot with residuals on the horizontal axis and fitted values on the vertical axis.\n\n[image:rId72]\n\n[Image:rId72] The image shows a scatter plot in GLM (General Linear Model) analysis using ECMiner, displaying fitted values against observed values. The plot includes residuals vs. fitted values, residual vs. order, and histogram plots for data analysis.\n\nHistogram Plot\n\nDistribution of residuals\n\n[image:rId73]\n\n[Image:rId73] The image shows a histogram plot generated by GLM in ECMiner, displaying the distribution of data points across different intervals. The plot indicates that most data points fall within the range of -48.3 to 71.8, with fewer points in other ranges. This visual representation helps in understanding the data\n\nResidual vs. Order Plot\n\nResiduals to the order of the data points.\n\n[image:rId74]\n\n[Image:rId74] The image shows a residual vs. fitted values plot in GLM (General Linear Model) analysis using ECMiner, displaying residuals for various intervals on a scatter plot with fitted values on the x-axis and residuals on the y-axis. The plot helps assess model fit by visualizing how well the model predicts the data points",
    "Context_id": "4장_v3_sanitized::chunk_0058",
    "Is_image": true,
    "Image_ids": [
      "rId70",
      "rId71",
      "rId72",
      "rId73",
      "rId74"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.3 Variance Analysis",
      "Result"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, focusing on Regression Analysis.",
    "Context_id": "4장_v3_sanitized::chunk_0059",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.4 Regression Analysis"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Regression Analysis, with a detailed reference to Multiple Linear Regression.\n\nMultiple Linear Regression predicts the dependent variable through the linear equation of two or more independent variables. MLR settings can be chosen between Stepwise or General where Stepwise technique combines Forward, Backward methods to iteratively add or remove variables, refining the model with significant predictors.",
    "Context_id": "4장_v3_sanitized::chunk_0060",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.4 Regression Analysis",
      "4.3.4.1 Multiple Linear Regression"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Regression Analysis, with a detailed reference to How to run.\n\n[Analyze] – [Regression Analysis] – [Multiple Linear Regression]\nSelect Dependent Variable from the dropdown selection box and Independent Variables through clicking the Variable Filter button. Then in the Model Setting, choose the Multiple Linear Regression technique between General and Stepwise. When Stepwise is chosen, also set the options of significance levels. Then click Execute button to see the results.\n[image:rId75]\n\n[Image:rId75] The image shows the production variance analysis window in ECMiner, where users can select dependent and independent variables, set model settings, and generate residual plots to assess model accuracy.",
    "Context_id": "4장_v3_sanitized::chunk_0061",
    "Is_image": true,
    "Image_ids": [
      "rId75"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.4 Regression Analysis",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Regression Analysis, with a detailed reference to Results.\n\nThe analysis results include Residual/Scatter Plots and MLR result table, where each result can be viewed through Plot and Table tab, respectively.\n[image:rId76]\n[image:rId77]\n[image:rId78]\n[image:rId79]\nBelow, the regression equation, ANOVA table, and Standard Error Information table are displayed.\n[image:rId80]\n\n[Image:rId76] The image shows an analysis of production variance using ECMiner, focusing on the relationship between A10 (dependent variable) and other variables (A1 to A9). The residual plot indicates no significant outliers, and the regression equation is provided along with ANOVA table results. Variables A1 and A6 were\n\n[Image:rId77] The residual plot in ECMiner shows the difference between actual values (Y) and predicted values (YHAT), indicating model accuracy and potential issues with outliers or non-linearity.\n\n[Image:rId78] The scatter plot in ECMiner shows a relationship between YHAT and Y, indicating a positive correlation with some outliers.\n\n[Image:rId79] The image is a screenshot of an Excel spreadsheet used for data analysis in ECMiner, a data mining software. It displays a table with columns labeled A2 to A13 and rows representing different datasets or samples. The data appears to be numerical values, possibly related to machine learning or statistical analysis, with some columns\n\n[Image:rId80] The image shows the results of a regression analysis using ECMiner, where variables A1 to A9 were included in the model after excluding multicollinear variables A1 and A6. The ANOVA table indicates that the model has a high R-squared value of 0.41384,",
    "Context_id": "4장_v3_sanitized::chunk_0062",
    "Is_image": true,
    "Image_ids": [
      "rId76",
      "rId77",
      "rId78",
      "rId79",
      "rId80"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.4 Regression Analysis",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Regression Analysis, with a detailed reference to Orthogonal Regression Analysis.\n\nOrthogonal regression assumes errors in both independent and dependent variables and minimizes the sum of squared orthogonal distances between the observations and the regression line. Unlike ordinary least squares (OLS), which only considers errors in the dependent variable, orthogonal regression accounts for errors in both variables, yielding a more accurate regression line.",
    "Context_id": "4장_v3_sanitized::chunk_0063",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.4 Regression Analysis",
      "4.3.4.2 Orthogonal Regression Analysis"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Regression Analysis, with a detailed reference to How to run.\n\n[Analyze] – [Regression Analysis] – [Orthogonal Regression Analysis]\nSelect Independent Variable and Dependent Variable and input Error Variance Ratio (Variance of the Dependent Variable’s Error/ Variance of the Independent Variable’s Error).\n[image:rId81]\n\n[Image:rId81] The image shows the Orthogonal Regression Test window in ECMiner, where users can specify independent and dependent variables for regression analysis, with an error variance ratio set to 1. The goal is to perform a regression test using these variables.",
    "Context_id": "4장_v3_sanitized::chunk_0064",
    "Is_image": true,
    "Image_ids": [
      "rId81"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.4 Regression Analysis",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Regression Analysis, with a detailed reference to Results.\n\nThe analysis results include the orthogonal regression equation, a regression coefficient estimates, and the error variance for each variable.\n[image:rId82]\nIn the Orthogonal regression line tab of the results window, you can view the graph of the observed values and the orthogonal regression line.\n[image:rId83]\n\n[Image:rId82] The Orthogonal regression test in ECMiner shows that there is no significant relationship between Y and X, with an error variance ratio of 1.000000. The regression equation is Y = 0.118106*X + 4.654017,\n\n[Image:rId83] The image shows an Orthogonal Regression Test in ECMiner, displaying a scatter plot with data points (red squares) and a fitted regression line (blue). The equation Y = 0.118106 * X + 4.654017 indicates a linear relationship between variables X",
    "Context_id": "4장_v3_sanitized::chunk_0065",
    "Is_image": true,
    "Image_ids": [
      "rId82",
      "rId83"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.4 Regression Analysis",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Regression Analysis, with a detailed reference to Nonlinear Regression.",
    "Context_id": "4장_v3_sanitized::chunk_0066",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.4 Regression Analysis",
      "4.3.4.3 Nonlinear Regression"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Regression Analysis, with a detailed reference to Overview.\n\nNonlinear Regression is applied when the relationship between the independent and dependent variables is nonlinear, with the regression equation expressed as a nonlinear function (such as polynomial, exponential, or logarithmic functions).\n\nNonlinear Least Square Regression\n\n[image:rId84]\n\n[Image:rId84] The image shows the objective function F(x) in ECMiner, which is used to optimize the model parameters x by minimizing the difference between the predicted values f_i(x) and the actual values y_i. The objective function is calculated as the sum of squared differences between the predicted and actual values, divided by 2\n\nECMiner™ Nonlinear Regression uses the Levenberg-Marquardt algorithm, a high-performance method widely used for nonlinear regression and optimization problems. The Levenberg-Marquardt algorithm performs an optimization process to minimize the Nonlinear Least Square Regression (as shown in the equation above) and efficiently adjusts parameters by combining the Gauss-Newton method and gradient descent.\n\nCurve Fitting in ECMiner™\n\nStandard Expression: ECMiner™ supports various standard regression analyses that can be linearized for parameter estimation and generally provides accurate predictions.\n\nPolynomial Function\n\nLogarithm Function\n\nExponential Function\n\nPower Law Function\n\nRational Function\n\nCustom Expression: If you input a desired function shape, the algorithm will find the best-fitting parameters.",
    "Context_id": "4장_v3_sanitized::chunk_0067",
    "Is_image": true,
    "Image_ids": [
      "rId84"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.4 Regression Analysis",
      "Overview"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Regression Analysis, with a detailed reference to How to run.\n\n[Analyze] – [Regression Analysis] – [Nonlinear Regression Analysis].\nSpecify either Custom Expression or Standard Expression.\n[image:rId85]\nIf you select the Standard Expression, define the independent and dependent variables.\n[image:rId85]\nWhen you specify variables, select the form of the function, and press the Run button, you can view the estimated results (plot and regression analysis results) as follows.\n[image:rId86]\nIf you select Residuals, the scatterplot of the time series data and fitted values. You can select different types of residuals.\n[image:rId87]\nIf you select the Custom Expression, click the [image:rId88] button and specify the formula you want.\n[image:rId88]\n(At this time, please note that the name of the parameter to be estimated must be written in the form @T1, @T2, etc.)\n[image:rId89]\nIf there are two variables used as independent variables above, the following 3D plot can be obtained as a result.\n[image:rId90]\nIf you select the Residuals radio button, you can view the actual time series data, fitted values, and residual trends as follows.\n[image:rId91]\n\n[Image:rId85] The image shows an ECMiner regression analysis setup where a polynomial equation is being fitted to data, with A2 as the dependent variable and A4 as the independent variable. The plot displays residuals for the regression model.\n\n[Image:rId86] The image shows an ECMiner data mining software window for regression analysis, displaying a scatter plot with a fitted polynomial equation A2 = 2.16932 - 0.00622 * {A4}, along with error metrics like RMSE, MAE, and MAPE.\n\n[Image:rId87] The image shows an ECMiner regression analysis where A2 is the dependent variable, A4 is the independent variable, and a polynomial equation is used for curve fitting. The residual plot indicates that the model fits well with minimal residuals.\n\n[Image:rId88] The image shows an ECMiner regression analysis setup with a custom equation, Levenberg-Marquardt method, and initial values for T1 and T2. The residual plot indicates no significant errors in the model.\n\n[Image:rId89] The image shows an Expression Editor window in ECMiner, where a user is entering an expression involving variables T1, T2, A2, and A4. The goal is to perform a calculation using these variables, likely for data analysis or mining purposes.\n\n[Image:rId90] The image shows an ECMiner data mining software window displaying a non-linear regression analysis with a scatter plot, showing a relationship between variables X1 and Y, and providing regression equation details like coefficients and error metrics.\n\n[Image:rId91] The image shows the results of a non-linear regression analysis using ECMiner software, with a focus on fitting a model to data in columns A29, A2, and A4. The equation used is @T1 + @T2*(A2)*(A4). The residual plot indicates that the model",
    "Context_id": "4장_v3_sanitized::chunk_0068",
    "Is_image": true,
    "Image_ids": [
      "rId85",
      "rId86",
      "rId87",
      "rId88",
      "rId89",
      "rId90",
      "rId91"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.4 Regression Analysis",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, focusing on SPC (Statistical Process Control).",
    "Context_id": "4장_v3_sanitized::chunk_0069",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.5 SPC (Statistical Process Control)"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection SPC (Statistical Process Control), with a detailed reference to Process Capability Analysis.\n\nProcess Capability Analysis is for evaluating whether data is distributed within the desired s p ecification.",
    "Context_id": "4장_v3_sanitized::chunk_0070",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.5 SPC (Statistical Process Control)",
      "4.3.5.1 Process Capability Analysis"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection SPC (Statistical Process Control), with a detailed reference to How to run.\n\n[Analyze] - [SPC] - [Process Capability Analysis]\n[image:rId92]\nClick [Settings] button, and select the target variable.\n[image:rId93]\nSelect Target Variable (multiple selections are possible) and set the LSL, USL, TSL, Subgroup Size, and Number of bins or histograms.\n\n[Image:rId92] The image shows the \"Process Capability Analysis\" window in ECMiner, a data mining software tool. It is used to analyze the capability of a process by comparing its output to a target value. The settings allow users to specify the number of samples (2) for both X and Y axes, and the \"Create\n\n[Image:rId93] The image shows the \"Process Capability Analysis Settings\" window in ECMiner, where users can configure settings for analyzing process capability, including target variables, specification limits (LSL, USL, TSL), subgroup size, and number of bins.",
    "Context_id": "4장_v3_sanitized::chunk_0071",
    "Is_image": true,
    "Image_ids": [
      "rId92",
      "rId93"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.5 SPC (Statistical Process Control)",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection SPC (Statistical Process Control), with a detailed reference to Results.\n\n[image:rId94]\n\n[Image:rId94] The image shows a Process Capability Analysis in ECMiner, displaying histograms and statistical metrics for four different datasets (A23, A29, A36, A45) to evaluate process performance and capability. The analysis includes Cp, Cpk, Pp, Ppk, and other quality control measures\n\n[Table:t524]",
    "Context_id": "4장_v3_sanitized::chunk_0072",
    "Is_image": true,
    "Image_ids": [
      "rId94"
    ],
    "Is_table": true,
    "Table_ids": [
      "t524"
    ],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.5 SPC (Statistical Process Control)",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection SPC (Statistical Process Control), with a detailed reference to Process Capability Result.\n\nProcess Capability Summary provides summary report for a specific field whether data is distributed within the desired process specification area.",
    "Context_id": "4장_v3_sanitized::chunk_0073",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.5 SPC (Statistical Process Control)",
      "4.3.5.2 Process Capability Result"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection SPC (Statistical Process Control), with a detailed reference to How to run.\n\n[Analyze] - [SPC] - [Process Capability Result]\n[image:rId95]\nClick [Settings] button, and select the target variable.\n[image:rId96]\nSelect Target Variable and set the LSL, USL, TSL, Subgroup Size, and Numbers of bins for multiple charts.\n\n[Image:rId95] The image shows the \"Process Capability Result\" window in ECMiner, displaying control charts for trend analysis and normal probability plots to evaluate process capability.\n\n[Image:rId96] The image shows the Process Capability Result window in ECMiner, displaying settings for LSL, USL, TSL, subgroup size, and number of bins, with variable names listed on the left. The main purpose is to analyze process capability by setting control limits and binning data for statistical analysis.",
    "Context_id": "4장_v3_sanitized::chunk_0074",
    "Is_image": true,
    "Image_ids": [
      "rId95",
      "rId96"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.5 SPC (Statistical Process Control)",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection SPC (Statistical Process Control), with a detailed reference to Results.\n\n[image:rId97]\n\n[Image:rId97] The image is a screenshot of an ECMiner data mining software process capability summary, displaying various charts including control chart, trend, and normal probability plot to evaluate process performance and identify potential issues.",
    "Context_id": "4장_v3_sanitized::chunk_0075",
    "Is_image": true,
    "Image_ids": [
      "rId97"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.5 SPC (Statistical Process Control)",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection SPC (Statistical Process Control), with a detailed reference to Acceptance Sampling.\n\nAcceptance Sampling is a technique that determines whether a lot accept or fails a sa m ple product randomly drawn from the lot. If you are counting defective or non-defective items, choose Attributes Acceptance Sampling. If you are testing a variable against a specific threshold to determine whether it is defective, choose Variable Acceptance Sampling.\n(1) Attributes Acceptance Sampling\n\nHow to run\n\n[Analyze] – [SPC] – [Acceptance Sampling] – [Attributes Acceptance Sampling],\n\nSelect General Sampling Plan. The result gives you the optimal sample size and number of acceptances. If you want to compare several sample sizes and number of acceptances, choose Comparison among User-defined acceptance sampling plan. The result will display sampling inspection plan using all the combinations of sample sizes and number of acceptances.\n\nSelect Measurement Type and Unit of Quality Level, and set a value.\n\n[image:rId98]\n\n[Image:rId98] The image shows the Attributes Acceptance Sampling window in ECMiner, where users can set parameters for quality control, such as measurement type, defect rate, acceptable and rejectable quality levels, producer and consumer risks, and lot size.\n\nResults\n\nAn optimal sampling inspection plan is suggested based on given criteria.\n\n[image:rId99]\n\n[Image:rId99] The image shows the Attributes Acceptance Sampling window in ECMiner, detailing a pass/fail quality control plan with specific defect rates, acceptance and failure levels, and sample sizes for statistical analysis.\n\nSelect Graphs bottom, OC curve, AOQ, and ATI charts are displayed.\n\n[image:rId100]\n\n[Image:rId100] The image shows the Attributes Acceptance Sampling module in ECMiner, displaying three graphs: Inspection characteristic (OC) curve, Average Entry and Exit Quality (AOQ) Curve, and Average Total Inspection (ATI) Curve. These graphs help in determining the optimal sampling plan for quality control by visualizing the probability of\n\n(2) Quantitative Acceptance Sampling\n\nHow to run\n\n[Analyze] – [SPC] – [Acceptance Sampling] – [Quantitative Acceptance Sampling].\n\nSelect General Sampling Plan. The result gives you the optimal sample size and critical distance. If you want to compare several sample sizes with specific critical distance, choose Comparison among User-defined quantitative sampling plan. The result will display sampling inspection plan using all the combinations of sample sizes and critical distance.\n\nFill all the blanks and define Unit of Quality Level.\n\n[image:rId101] [image:rId102]\n\n[Image:rId101] The image shows the \"Quantitative Acceptance Sampling\" window in ECMiner, where users can set parameters for sampling quality levels. The unit of quality level is set to \"Defect rate (%),\" with an acceptable quality level of 1.5% and a rejectable quality level of 3%. The lot\n\n[Image:rId102] The image shows the \"Quantitative Acceptance Sampling\" window in ECMiner, where users can set parameters for comparing defect rates among lots. The user has specified an acceptable quality level of 1.5%, a rejectable quality level of 3%, and a lot size of 2700 units.\n\nResults\n\nThe Quantitative Acceptance Sampling results is as follows.\n\nAn optimal sampling inspection plan is given based on given criteria.\n\n[image:rId103]\n\n[Image:rId103] This screen in ECMiner's Quantitative Acceptance Sampling module displays pass sampling plan information, including defect rates, acceptance quality levels, failure quality levels, lot size, sample size, critical distance, and generated sampling plans with corresponding probabilities and quality metrics for different defect rates.\n\nSelect Graphs bottom, OC curve, AOQ, and ATI charts are displayed.\n\n[image:rId104]\n\n[Image:rId104] The image shows the Quantitative Acceptance Sampling module in ECMiner, displaying three graphs: an Inspection characteristic (OC) curve, Average Entry and Exit Quality (AOQ) curve, and Average Total Inspection (ATI) curve. These curves help in determining the optimal sampling plan for inspecting batches to ensure quality",
    "Context_id": "4장_v3_sanitized::chunk_0076",
    "Is_image": true,
    "Image_ids": [
      "rId98",
      "rId99",
      "rId100",
      "rId101",
      "rId102",
      "rId103",
      "rId104"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.5 SPC (Statistical Process Control)",
      "4.3.5.3 Acceptance Sampling"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection SPC (Statistical Process Control), with a detailed reference to Tolerance Intervals.",
    "Context_id": "4장_v3_sanitized::chunk_0077",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.5 SPC (Statistical Process Control)",
      "4.3.5.4 Tolerance Intervals"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection SPC (Statistical Process Control), with a detailed reference to How to run.\n\n[Analyze] – [SPC] – [Tolerance Intervals]\nSelect the variable to get Tolerance Intervals from the Variable Selection list (multiple selections are possible), and set the Confidence Level and Coverage Proportion (0 to 1 value). Finally, select the Interval Direction (Both Side/Upper Limit/Lower Limit).\n[image:rId105]\n\n[Image:rId105] The image is from the Tolerance Intervals section in ECMiner, showing variable selection options for confidence level, coverage proportion, and interval direction. The user can choose which variables to include in the tolerance intervals analysis.",
    "Context_id": "4장_v3_sanitized::chunk_0078",
    "Is_image": true,
    "Image_ids": [
      "rId105"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.5 SPC (Statistical Process Control)",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection SPC (Statistical Process Control), with a detailed reference to Results.\n\nStatistics: average, and standard deviation.\n\nTolerance Intervals: Satisfy the specified Confidence Level and Coverage Proportion from the selected variable are calculated and displayed using normal distribution or non-parametric methods.\n\nNormality Test: Use the Anderson-Darling statistics test whet h er the selected variable follows a normal distribution. If the p-value is closed to 1, the variable follows a normal distribution.\n\n[image:rId106]\nHistogram: A chart for distribution of the selected variable.\n[image:rId107]\n\n[Image:rId106] The image shows the results of tolerance intervals analysis in ECMiner, indicating that 95% of the population falls within the given limits for variable A6 with a confidence level of 0.95. The data count is 8530, average is 49.9528,\n\n[Image:rId107] The image shows a histogram labeled \"Histogram of A6\" in ECMiner, displaying the distribution of values for variable A6 with tolerance intervals. The x-axis represents the range of values, and the y-axis shows the frequency of occurrences. The histogram illustrates how frequently different ranges of A6 values appear within the dataset",
    "Context_id": "4장_v3_sanitized::chunk_0079",
    "Is_image": true,
    "Image_ids": [
      "rId106",
      "rId107"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.5 SPC (Statistical Process Control)",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, focusing on Time Series Analysis.",
    "Context_id": "4장_v3_sanitized::chunk_0080",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to Time Series Models.\n\n(1) Time Series Decomposition\nOverview\nTime series decomposition means dividing the data into components. Specifically, time series data can have components such as trend and seasonality, and these components can be extracted and separated. Classical decomposition includes multiplicative and additive decomposition.\nThe structure of classical decomposition methods is as follows.\nThe statistics obtained through decomposition are summarized as follows.\nMultiplicative Decomposition (Including Trend)\nThe Multiplicative Decomposition Model has the following form.\nAdditive Decomposition (Including Trend)\nThe Additive Decomposition Model has the following form.\nAt this point, the trend can be excluded from the analysis.\n\n[Table:t604]\n\n[Table:t607]\n\n[Table:t611]\n\n[Image:rId108] The image shows the ECMiner software's data mining interface, displaying a matrix transformation process where data is processed through three stages: TRX, SNX, and CLx, before being multiplied by an inverse matrix (IR). This represents a complex data analysis workflow in machine learning and data science.\n\n[Table:t615]",
    "Context_id": "4장_v3_sanitized::chunk_0081",
    "Is_image": true,
    "Image_ids": [
      "rId108"
    ],
    "Is_table": true,
    "Table_ids": [
      "t604",
      "t607",
      "t611",
      "t615"
    ],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "4.3.6.1 Time Series Models"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to How to run.\n\n[Analyze] – [Time Series Analysis] – [Time Series Models] – [Time Series Decomposition]\n[image:rId109]\nSelect time series data on the main screen, select the length of the season, and whether to use Multiplicative Decomposition or Additive Decomposition, and then select either Trend+Seasonal or Seasonal. If you want a forecast, click Generate Forecast and enter Forecast Lag.\n\n[Image:rId109] The image shows the \"Time Series Sample\" window in ECMiner, a data mining software tool. It is used for identifying time series models, specifically focusing on trend and seasonal components. The user can select between multiplicative and additive models, generate forecasts, and decompose time series data into its underlying components.",
    "Context_id": "4장_v3_sanitized::chunk_0082",
    "Is_image": true,
    "Image_ids": [
      "rId109"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to Results.\n\nModel Report\n\nGeneral Info: Shows basic information about time series data.\n\nModel Info: The forecast results are displayed when the trend and/or seasonality are selected in the Generate Forecast.\n\n[image:rId110]\n\n[Image:rId110] The image shows the Time Series Sample window in ECMiner, displaying time series decomposition results with a fitted trend equation and seasonal indices for forecasting purposes.\n\nPlot\n\nThis function is provided for visual interpretation of data obtained through Time Series Decomposition. Time Series Decomposition provides Decomposition results, time series property and Residual plots.\n\n[image:rId111]\n\n[Image:rId111] The image shows the Time Series Decomposition Plot in ECMiner, used to analyze and forecast time series data. It displays the decomposition into trend, seasonality, and residual components, with forecasts generated for the next 1000 time points.\n\nTime Series Decomposition Plot shows Original Data, Fitted Data.\n\n[image:rId112]\n\n[Image:rId112] The image shows a Time Series Sample window in ECMiner, where users can analyze time series data for trend, seasonality, and forecast generation. The plot displays fitted values over time, with a focus on multiplicative trends and seasonal patterns. Users can generate forecasts using a specified forecast lag.\n\nThe Time Series Property Plot shows each decomposed component as a plot. You can view all data at once, or view graphs for each piece of data separately.\n\n[Table:t638]\n\n[Image:rId115] The image is a residual vs. order plot from ECMiner, showing residuals on the y-axis and order numbers on the x-axis. The plot indicates that there is a general trend in the residuals, suggesting potential issues with the model's fit to the data.\n\n[Image:rId116] The image is a residual vs. fitted values plot from ECMiner, showing residuals on the y-axis and fitted values on the x-axis. The plot indicates that the model's predictions are generally close to the actual values, with most points clustered around the zero line, suggesting good fit and minimal error.\n\n[Image:rId113] The Residual Histogram in ECMiner data mining software displays the distribution of residuals, showing how well the model fits the data. The histogram indicates that most residuals fall within the range of -2.0e+05 to 3.92e+05, with a peak around -7.9\n\n[Image:rId114] The image shows a residual normal probability plot in ECMiner, used to assess the normality of residuals in a regression model. The plot compares observed residuals against their expected values under the assumption of normality, with a red line representing the theoretical normal distribution. The scatter of points around the line indicates whether the residuals are\n\nThrough Residual Plot (Histogram, Normal Probability Plot, Residual vs. Order, Residual vs. Fitted Values), you can analyze the residuals obtained as a result of decomposition.\n\nStatistics\n\nData obtained through Time Series Decomposition analysis is displayed in table form. It also provides a function to save it.\n\n(2) Moving Average\nOverview\nThe Moving Average method refers to the average value of several data from the present, past, and future. The method is a widely used one in its simplest form along with its expanded Centered Moving Average.",
    "Context_id": "4장_v3_sanitized::chunk_0083",
    "Is_image": true,
    "Image_ids": [
      "rId110",
      "rId111",
      "rId112",
      "rId115",
      "rId116",
      "rId113",
      "rId114"
    ],
    "Is_table": true,
    "Table_ids": [
      "t638"
    ],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to How to run.\n\n[Analyze] – [Time Series Analysis] – [Time Series Models] – [Moving Average]\n[image:rId117]\nSelect Time Series Data on the main screen and enter the length of the Moving Average, Centered Moving Average option, and Forecast Lag if you want to make a forecast. After completing the input, click the [Start Moving Average Analysis] button.\n\n[Image:rId117] The image shows the \"Moving Average Configuration\" window in ECMiner, used for analyzing time series data by applying moving averages to smooth out fluctuations and identify trends.",
    "Context_id": "4장_v3_sanitized::chunk_0084",
    "Is_image": true,
    "Image_ids": [
      "rId117"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to Results.\n\nModel Report\n\nGeneral Info: Provides basic information about time series data.\n\nModel Info: Provides information on the results of the Moving Average analysis. You can also view the results of the prediction accuracy based on MAPE, MAE and MSD.\n\n[image:rId118]\n\n[Image:rId118] The image shows the \"Exponential Smoothing\" model settings in ECMiner, with parameters like smoothing type, level, trend, and seasonal length configured for forecasting. The accuracy measures (MAPE, MAE, MSD) indicate the model's performance, while forecast results provide future predictions.\n\nPlot\n\nYou can visually view the data obtained as a result of Moving Average.\n\n[image:rId119]\n\n[Image:rId119] The image shows the ECMiner software's Time Series Sample window, where users can analyze time series data with options for moving average configuration, including centered moving average and forecast generation. The main purpose is to visualize and analyze time series data trends, with a focus on forecasting future values using a moving average method.\n\nMoving Average plot shows time series data, fitted values, and prediction-related statistics.\n\nYou can get the results the following Residual Plots (Histogram, Normal Probability Plot, Residual vs. Order, Residual vs. Fitted Values).\n\n[Table:t668]\n\n[Image:rId120] The Residual Histogram in ECMiner data mining software displays the distribution of residuals, showing how they are spread across different ranges. The histogram indicates that most residuals fall within the range of -3.41e+04 to 3.36e+05, with a peak around -0.\n\n[Image:rId121] The image shows a residual normal probability plot in ECMiner, used to assess the normality of residuals in a statistical model. The plot compares observed residuals against their expected values under the assumption of normality, with a red line representing the theoretical normal distribution. The data points are plotted along the x-axis as residuals and\n\n[Image:rId122] The image is a residual vs. order scatter plot generated by ECMiner, showing residuals on the y-axis and order numbers on the x-axis. The plot indicates that there is a general trend where residuals increase with increasing order numbers, suggesting potential issues in the model's fit to the data.\n\n[Image:rId123] The image is a residual vs fitted values plot from ECMiner, showing residuals on the y-axis and fitted values on the x-axis. The plot indicates that the model's predictions are generally close to the actual values, with some outliers present.\n\nStatistics\n\nData obtained through Moving Average analysis is displayed in table form. It also provides a function to save it.\n\n(3) Exponential Smoothing\nOverview\n\nSingle Exponential Smoothing\n\nThe following model has a constant term without any trend,\n\n[image:rId124]\n\n[Image:rId124] The image shows a regression equation in the form y = β₀ + ε_t, where y is the dependent variable, β₀ is the intercept, ε_t is the error term, and t represents time. This equation represents a linear relationship between the dependent variable y and an independent variable or set of variables over time.\n\nUsing the least squares method, we have the estimate for the co n stant parameter.\n\n[image:rId125]\n\n[Image:rId125] The image shows the output of ECMiner, a data mining tool, displaying the estimated parameter β̂_o = y̅, which represents the average value of y across all iterations n. This indicates that the software has calculated an average outcome for a specific dataset or model.\n\nIf you look at the above equation, you can see that in the process of calculating the estimate for [image:rId126], the same size weight (1/n) is assigned to all observations, but this does not seem reasonable. So the idea of exponential smoothing is to give more weight to recent data and less weight to older data. Among these exponential smoothing methodologies, the one that processes data without trends and seasonality is Single Exponential Smoothing.\n\n[Image:rId126] The image shows the ECMiner software interface, which is used for data mining and analysis. It displays various options and settings for configuring the mining process, including parameters like the number of iterations, learning rate, and feature selection criteria. The main purpose is to automate the discovery of patterns and relationships within large datasets by applying\n\nDouble Exponential Smoothing\n\nLet’s consider the following time series model.\n\n[image:rId127]\n\n[Image:rId127] The image shows the output of an ECMiner data mining software, displaying the results of a regression analysis with two independent variables, β₀ and β₁, and an error term ε. The y-values represent the predicted values based on the model.\n\nIf [image:rId128] are the parameters with fixed values, the parameters can be estimated by the least squares estimation, for example. On the other hand, if [image:rId128] can change over time, Double Exponential Smoothing is proposed to explain this model.\n\n[Image:rId128] The image shows the ECMiner software interface, specifically the \"Model\" tab where users can view and manage their mined models. It displays two coefficients, β₀ and β₁, which represent parameters in a statistical model used for data mining tasks such as classification or regression analysis. The coefficients help in understanding the relationship between\n\nWinters’ Method: Multiplicative Winters’ Method\n\nThe Multiplicative Winters’ method is a time series model that considers seasonality as well as level and trend. The Multiplicative Winters’ Method is known to be suitable for forecasting of time series expressed by the following equation.\n\n[image:rId129]\n\n[Image:rId129] The image shows the output of ECMiner, a data mining tool, displaying the results of a regression analysis. The main purpose is to predict values based on input variables. The content includes coefficients (\\(\\beta_0\\), \\(\\beta_1\\)), residuals (\\(\\epsilon_i\\)), and standardized residuals (\\\n\nWinters’ Method: Additive Winters’ Method\n\nThe Additive Winters’ method is known to be most suitable for forecasting of time series data that satisfies the following equation.\n\n[image:rId130]\n\n[Image:rId130] The image shows the output of ECMiner, a data mining tool, displaying the results of a clustering analysis. The main purpose is to identify patterns in the data by grouping similar items together. The content includes:\n- β₀: A constant term\n- β₁: A coefficient for a linear term\n- t\n\nThe Additive Winters’s Method can be obtained by slightly modifying the Multiplicative one.",
    "Context_id": "4장_v3_sanitized::chunk_0085",
    "Is_image": true,
    "Image_ids": [
      "rId118",
      "rId119",
      "rId120",
      "rId121",
      "rId122",
      "rId123",
      "rId124",
      "rId125",
      "rId126",
      "rId127",
      "rId128",
      "rId129",
      "rId130"
    ],
    "Is_table": true,
    "Table_ids": [
      "t668"
    ],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to How to run.\n\n[Analyze] – [Time Series Analysis] – [Time Series Models] – [Exponential Smoothing]\n[image:rId131]\nOn the main screen, select Time Series Data and select which smoothing type to use. At this time, when using Single Exponential Smoothing, the user can enter the level value directly, or check ‘Use Optimal Level’ to automatically enter the optimal level value between 0 and 1. When selecting Double Exponential Smoothing, enter level and trend smoothing constants. When using the Winters’ Method, select multiplicative and additive and enter level, trend, seasonal smoothing constants, and seasonal length. If you want to make a prediction, please enter Forecast Lag.\n\n[Image:rId131] The image shows the settings for exponential smoothing in ECMiner, specifically using Winters' Exponential Smoothing method with target data. Parameters include level, trend, seasonal components, and forecast generation with a lag of 1000. The goal is to analyze and predict time series data trends.",
    "Context_id": "4장_v3_sanitized::chunk_0086",
    "Is_image": true,
    "Image_ids": [
      "rId131"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to Results.\n\nModel Report\n\nGeneral Info: Shows basic information about time series data.\n\nModel Info: Provides information obtained through exponential smoothing analysis. You can also view the results of the prediction accuracy based on MAPE, MAE and MSD.\n\n[image:rId118]\n\nPlot\n\nYou can visually view the data obtained as a result of Exponential Smoothing analysis.\n\n[image:rId132]\n\n[Image:rId132] The image shows an Exponential Smoothing plot in ECMiner, analyzing time series data with parameters like Level, Trend, Seasonal, and Forecast Lag set to specific values. The plot compares observed values (Y_Observation) with predicted values (y_PredUB and y_PredLB) over time,\n\nThe Exponential Smoothing Plot allows you to view the time series data, fitted values, and the forecast-related values.\n\n[Table:t712]\n\n[Image:rId136] The image is a residual vs fitted values plot from ECMiner, showing residuals on the y-axis and fitted values on the x-axis. The plot indicates that the model's predictions are generally close to the actual values, with some outliers present.\n\n[Image:rId133] The residual histogram in ECMiner shows the distribution of residuals, indicating how well the model fits the data. The peak at around -2.4e+05 suggests that most residuals fall within this range, with fewer outliers.\n\n[Image:rId134] The image shows a residual normal probability plot from ECMiner, used to assess the normality of residuals in a statistical model. The plot compares observed residuals against their expected values under the assumption of normality, with a red line representing the theoretical normal distribution. The scatter of points around the line indicates that the residuals are\n\n[Image:rId135] The image shows a residual vs. order plot in ECMiner, indicating that the residuals are not randomly distributed but rather show some clustering, suggesting potential issues with the model's fit to the data.\n\nYou can get the results the following Residual Plots (Histogram, Normal Probability Plot, Residual vs. Order, Residual vs. Fitted Values) in the Exponential Smoothing analysis.\n\nStatistics\n\nThe statistics obtained as a result of the Exponential Smoothing analysis can be seen in the table. It also provides the function to save it.\n\n(4) ARIMA\nOverview\n\nThe ARIMA model is the most commonly used model in Univariate Time Series Analysis and satisfies the following equation. In case of ARIMA(p, d, q),\n\n[image:rId137]\n\n[Image:rId137] The image shows an equation used in ECMiner, a data mining software, to model the relationship between variables. The equation represents a function that combines parameters θ and β with a power-law term involving the standard deviation of the noise variable a_t, which is assumed to be independent and identically distributed (i.i\n\n[image:rId138]\n\n[Image:rId138] The image shows a complex mathematical formula used in ECMiner, a data mining software, to calculate the difference between two sets of data points (B and B^P) with respect to their respective parameters (phi). The formula involves multiple terms, including the product of phi values, the difference between B and B^\n\n[image:rId139]\n\n[Image:rId139] The image shows a screenshot of the ECMiner data mining software, displaying a complex mathematical equation used for feature selection in machine learning. The equation involves multiple variables, including z_t and a_t, with coefficients θ_i and B^d, representing weights and biases in a linear model. This equation is part of\n\nthe purpose is to estimate the coefficients from the above equation, test the suitability of the equation created using the estimated coefficients, and finally perform forecasting.\n\nBox-Jenkins’ Method\n\nBox and Jenkins explained the processes of Time Series Analysis in the following ways.\n\n1. From the interaction of theory and practice, a useful class of models for the purposes at hand is considered.\n\n2. Because this class is too expensive to be conveniently fitted directly to data, rough methods for identifying subclass of these models are developed. Such methods of model identification employ data and knowledge of the system to suggest an appropriate parsimonious subclass of models which may tentatively entertained. In addition, the identification process can be used to yield rough preliminary estimates of the parameters in the model.\n\n3. The tentatively entertained model is fitted to the data and the parameters in the model are to be estimated. The estimates obtained during the identification stage can now be used as initial values in more refined iterative methods for estimating the parameters.\n\n4. Diagnostic checks are applied with the object of uncovering possible lack of fit and diagnosing the cause. If no lack of fit is indicated, the model is ready to use. If any inadequacy is found, the iterative cycle of identification, estimation, and diagnostic checking is repeated until a suitable representation is found.\n\n[image:rId140]\n\n[Image:rId140] The image illustrates the process of model selection in ECMiner, starting with postulating general classes of models, then identifying a tentative model, estimating its parameters, performing diagnostic checks to ensure adequacy, and finally using the model for forecasting or control.\n\nTo put it simply,\n\n1. Assume a general model (ARIMA, ARCH, for example).\n\n2. Determine a candidate model (such as ARIMA(1,1,1)) from the models.\n\n3. Estimate the parameters of the model.\n\n4. Verify suitability, and further work such as forecasting is carried out.",
    "Context_id": "4장_v3_sanitized::chunk_0087",
    "Is_image": true,
    "Image_ids": [
      "rId118",
      "rId132",
      "rId136",
      "rId133",
      "rId134",
      "rId135",
      "rId137",
      "rId138",
      "rId139",
      "rId140"
    ],
    "Is_table": true,
    "Table_ids": [
      "t712"
    ],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to How to run.\n\n[Analyze] – [Time Series Analysis] – [Time Series Models] – [ARIMA]\n[image:rId141]\nOn the ARIMA main screen, you can run the Model Identification process and ARIMA Model Estimation process. Through Model Identification, you can see the autocorrelation, partial autocorrelation, and scatter plot of the differential time series data, which can help users determine the orders of the ARIMA model needed when estimating the ARIMA model. Below are examples of autocorrelation, partial autocorrelation, and scatter plot.\n[image:rId142]\n[image:rId143]\n[image:rId144]\nIn this way, models are identified and orders are determined through Autocorrelation, Partial Autocorrelation, and Scatter Plot. If you click the Options button, you can select the ARIMA methodology (Conditional Least Square, Maximum Likelihood) as follows and enter constant settings related to Levenberg Marquardt used for Parameter Optimization, and initialization method.\n[image:rId145]\nAnd when you start Time Series Analysis, you can get the following results:\n\n[Image:rId141] The image shows the Time Series Sample window in ECMiner, used for analyzing time series data with ARIMA model estimation options. It allows users to specify parameters like differencing, AR, MA orders, and forecast generation for non-seasonal models.\n\n[Image:rId142] The image shows the Autocorrelation Function (ACF) plot in ECMiner, used to identify ARIMA model parameters for time series data analysis. The ACF plot indicates strong autocorrelation at lag 1, suggesting an AR(1) model might be appropriate.\n\n[Image:rId143] The image shows the Time Series Sample window in ECMiner, used for analyzing time series data. It includes options for model identification, ARIMA model estimation, and a Partial Autocorrelation Function (PACF) chart to identify appropriate model parameters. The PACF plot helps determine the order of autoregressive\n\n[Image:rId144] The image shows an ARIMA model identification process in ECMiner, with a scatter plot displaying time series data for forecasting purposes. The user is analyzing a dataset to identify appropriate ARIMA parameters for modeling and predicting future values.\n\n[Image:rId145] The ARIMA Methodology Selection window in ECMiner is used to configure parameters for time series analysis, with options for Maximum Likelihood estimation and Levenberg-Marquardt optimization, allowing users to adjust epsilon values and initialization methods.",
    "Context_id": "4장_v3_sanitized::chunk_0088",
    "Is_image": true,
    "Image_ids": [
      "rId141",
      "rId142",
      "rId143",
      "rId144",
      "rId145"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to Results.\n\nModel Report\n\nGeneral Info: Shows basic information about time series data.\n\nModel Info: Provides the results of Time Series Analysis. You can obtain model shape information, parameter information, Parameter Optimization results, and forecast results.\n\nResidual Autocorrelation Function: You can perform a diagnostic check through the Residual Autocorrelation Function and Residual Partial Autocorrelation Function.\n\n[image:rId146]\n\n[Image:rId146] The image shows the Time Series Analysis ARIMA module in ECMiner, which identifies an ARIMA model with non-seasonal order 0, seasonal order 1, and MA order 1. It estimates parameters for SAR(1) and SMA(1), with t-values and p-values indicating statistical significance. The\n\nPlot\n\nData obtained through ARIMA models can be visually analyzed. Through a time series plot, you can see observed values, fitted values, predicted values, and upper and lower prediction limits.\n\n[image:rId147]\n\n[Image:rId147] The image shows the Time Series Sample window in ECMiner, where ARIMA model estimation is being performed on time series data. The user has selected to include seasonal components with a base lag of 365 days and specified non-seasonal parameters for AR and MA orders. The plot displays the final results, including\n\nYou can perform residual analysis for diagnostic check through the following residual plots.\n\n[Table:t774]\n\n[Image:rId149] The image shows a residual normal probability plot in ECMiner, used to assess the normality of residuals after fitting a model. The plot compares observed residuals against their expected values under the assumption of normality, with a red line representing the ideal normal distribution. The scatter of points around the line indicates whether the residuals are\n\n[Image:rId150] The image shows a residual vs. order plot in ECMiner, indicating that the model's predictions are generally close to the actual values, with some outliers present.\n\n[Image:rId151] The image shows a scatter plot titled \"Fitted Value vs. Residual,\" which is used to evaluate the goodness of fit in regression analysis. The x-axis represents the fitted values, while the y-axis shows the residuals. The plot indicates that the residuals are randomly distributed around zero, suggesting that the model fits the data\n\n[Image:rId148] The residual histogram in ECMiner shows the distribution of residuals, with most values clustered around -1.9e+05 to 9.65e+05, indicating that the model's predictions are generally close to the actual data points.\n\nStatistics\n\nThrough Statistics Information, you can view the data obtained after creating the model in a table. It also provides a function to save the information obtained in this way.\n\n(5) Trend Analysis\nOverview\nTrend analysis is a methodology performed to obtain basic trends in time series data. Time series data observed at each point in time are created under the logic that they are explained only by functional relationships with time as the horizontal axis and observed values as the vertical axis. Let us limit these functional relationships to the following.\nAll parameters estimated for each function are obtained in closed form through the Least Square method.\n\n[Table:t783]",
    "Context_id": "4장_v3_sanitized::chunk_0089",
    "Is_image": true,
    "Image_ids": [
      "rId146",
      "rId147",
      "rId149",
      "rId150",
      "rId151",
      "rId148"
    ],
    "Is_table": true,
    "Table_ids": [
      "t774",
      "t783"
    ],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to How to run.\n\n[Analyze] – [Time Series Analysis] – [Time Series Models] – [Trend Analysis]\nIn the window, select what type of function to fit, and if you want to make a forecast, enter Forecast Lag and click the Start Trend Analysis button.\n[image:rId152]\n\n[Image:rId152] The image shows the Trend Analysis interface in ECMiner, where users can select linear, quadratic, exponential, or logarithmic models for time series data, generate forecasts, and specify forecast lags.",
    "Context_id": "4장_v3_sanitized::chunk_0090",
    "Is_image": true,
    "Image_ids": [
      "rId152"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to Results.\n\nModel Report\n\nGeneral Info: Shows basic information about time series data.\n\nModel Info: Provides regression equations, accuracy measures, and forecast results obtained through trend analysis.\n\n[image:rId153]\n\n[Image:rId153] The image shows the Trend Analysis section in ECMiner, displaying model information, regression equation, accuracy measures (MAPE, MAD, MSD), and forecast results for time series data with linear trend analysis.\n\nPlot\n\nVisually displays the original and fitted data obtained through trend analysis.\n\n[image:rId154]\n\n[Image:rId154] The image shows a Time Series Analysis window in ECMiner, displaying a linear trend analysis with two series: Y_Observation (pink line) and Y_HAT (blue line). The goal is to identify patterns and forecast future values based on historical data.\n\nThrough the Time Series Plot, you can see the time series data and the regression line that estimates it at a glance.\n\n[Table:t803]\n\n[Image:rId157] The image is a residual vs. order plot from ECMiner, showing residuals on the y-axis and order on the x-axis. The plot indicates that there is a pattern in the residuals, suggesting potential issues with the model's fit to the data.\n\n[Image:rId158] The image shows a residual vs fitted values plot in ECMiner, which is used to evaluate the goodness of fit for a statistical model. The plot displays residuals on the y-axis against fitted values on the x-axis, with a trend line indicating how well the model fits the data points.\n\n[Image:rId155] The Residual Histogram in ECMiner data mining software displays the distribution of residuals, showing how well the model fits the data. The histogram categorizes residuals into intervals, with each bar representing the count of residuals within that interval. This helps identify any patterns or outliers in the residuals, indicating areas where the model may need\n\n[Image:rId156] The image shows a residual normal probability plot in ECMiner, used to assess the normality of residuals in a statistical model. The plot compares observed residuals against their expected values under the assumption of normality, with a fitted line indicating how well the residuals follow a normal distribution.\n\nResidual Plot (Histogram, Normal Probability Plot, Residual vs. Order, Residual vs. Fitted Values) allows you to analyze residuals obtained by Trend Analysis.\n\nStatistics\n\nStatistics obtained through trend analysis can be viewed in the table. In addition, it also provides the function to save tables.\n\n(6) GARCH\nOverview\nThe ARCH (Autoregressive Conditional Heteroskedasticity) methodology was proposed in the 1980s, and Robert Engle, who proposed this method, received the Nobel Prize in Economics in 2003. The innovative aspect of this methodology is to modify the assumption that random shocks have constant variance in the time series analysis so far, and introduce the assumption that random shocks have constant variance unconditionally, but the conditional variance depend on time t. Robert Engle proposed the ARCH Model in 1982, and the generalized ARCH model, that is, the GARCH model, was proposed by Bollerslev in 1986 and various modified models such as EGARCH, GARCH-M, and GJR have been presented since then. The reason why many modified models of ARCH have been presented and received a lot of attention is because with the development of financial economics, not only time series prediction but also measurement and prediction of volatility (variance) have become very important. In many capital asset pricing models, the volatility of the underlying asset has been considered an important factor affecting the price of the asset, but the methodology for measuring and predicting this volatility had not been developed before ARCH. Research related to this has continued steadily not only in the 1980s, but also since then, and even recently, the GARCH model is now used in various engineering fields, especially network traffic analysis, in addition to financial economics.",
    "Context_id": "4장_v3_sanitized::chunk_0091",
    "Is_image": true,
    "Image_ids": [
      "rId153",
      "rId154",
      "rId157",
      "rId158",
      "rId155",
      "rId156"
    ],
    "Is_table": true,
    "Table_ids": [
      "t803"
    ],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to How to run.\n\n[Analyze] – [Time Series Analysis] – [Time Series Models] – [GARCH]\nOn the main screen, enter the basic information required for GARCH analysis. Select Dependent Variable (Response Variable) and Independent Variable (Explanatory Variable) and select ARCH order and GARCH order. Finally, choose whether you want to generate predictions or not and you're all set.\n[image:rId159]\nMore specific settings can be set in the Option window below.\n[image:rId160]\nGARCH's Parameter Estimation is very demanding. In some cases, Estimation frequently ends at Local Optimum. Therefore, ECMiner™ presents several optimization methodologies for users to choose from. Users can perform optimization using multiple methodologies and choose the best solution. Parameter settings are options to set when performing the optimization algorithm. Forecast-related options determine which data to use for modeling. The initial value selection method determines how to select the initial value.\n\n[Image:rId159] The image shows the GARCH Model Estimation window in ECMiner, used for analyzing time series data to predict temperature trends by selecting dependent and independent variables like \"Predicted Temp\" and \"Real Temp.\"\n\n[Image:rId160] The image shows the optimization settings window in ECMiner, where users can select an optimization method (MMA), set tolerance, numerical delta, and maximum values for parameter adjustments, and choose initialization selection methods. The interface is designed to fine-tune model parameters for better forecasting accuracy.",
    "Context_id": "4장_v3_sanitized::chunk_0092",
    "Is_image": true,
    "Image_ids": [
      "rId159",
      "rId160"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to Results.\n\nModel Report\n\nGeneral Info: Shows basic information about time series data.\n\nModel Info: Provides parameters, statistics, and forecast results obtained through GARCH analysis.\n\nResidual Chart: Shows Residual Autocorrelation Function, Residual Partial Autocorrelation Function.\n\n[image:rId161]\n\n[Image:rId161] The image shows the Time Series Analysis GARCH Model Information page in ECMiner, which estimates GARCH parameters for time series data. The model includes ARCH(1) and GARCH(1) components with coefficients and standard errors displayed.\n\nPlot\n\nVisually displays data obtained through GARCH analysis. Shows Time Series Plot, squared residual, conditional volatility, and plots for residuals (Histogram, Normal Probability Plot, Residual vs. Order, Residual vs. Fitted Values).\n\nBelow is an example of a Time Series Plot. You can see time series data, fitted values, and the upper and lower limits of the fitted values at a glance.\n\n[image:rId162]\n\n[Image:rId162] The image shows an ECMiner data mining software interface for time series analysis, specifically focusing on GARCH model estimation. It displays a plot chart with three lines representing different forecasted temperature values: Y, Y_HAT, and two uncertainty intervals (Y_UCL and Y_LCL). The software is used to analyze\n\nThe plot below is a conditional volatility plot. You can view the conditional volatility value resulting from modeling. (If you make a prediction, the predicted value of conditional volatility will also appear.)\n\n[image:rId163]\n\n[Image:rId163] The image shows an ECMiner software interface for analyzing time series data, specifically focusing on conditional volatility estimation using a GARCH model. The user is viewing a plot chart with conditional volatility data over time, indicating fluctuations in volatility levels.\n\nThe plot below is a squared residual plot. You can see the value of the squared residual, as a result of modeling.\n\n[image:rId164]\n\n[Image:rId164] The image shows an ECMiner software interface for analyzing time series data, specifically focusing on residual squares in a GARCH model. The user is examining predicted temperature data against real temperature, with the goal of assessing the accuracy of the model's predictions.\n\nIn addition, you can check normality through four residual plots.\n\n[Table:t841]\n\n[Image:rId168] The image is a scatter plot from ECMiner, showing the relationship between fitted values and residuals in a regression analysis. The plot indicates that there is a positive correlation between the two variables, with most points clustered around a line, suggesting that the model fits the data well.\n\n[Image:rId165] The residual histogram in ECMiner shows the distribution of residuals, with most values clustered around -1.87 to 2.9, indicating a normal distribution.\n\n[Image:rId166] The Residual Normal Probability plot in ECMiner shows residuals on the x-axis and z-values on the y-axis, with a line representing normal distribution. The plot evaluates model residuals for normality, indicating whether the model assumptions are met.\n\n[Image:rId167] The image shows a residual vs. order plot in ECMiner, indicating that the residuals are not randomly distributed but show some patterns, suggesting potential issues with the model's fit to the data.\n\nStatistics\n\nStatistics obtained through GARCH analysis can be seen in the table. In addition, it also provides the function to save tables.\n\n(7) VAR\nOverview\nIn empirical analysis, it is often advantageous to model two or more time series simultaneously. If sets of specific variables do not simply move individually but are influenced by each other, a model can be assumed as follows. This is called the Vector Autoregressive (VAR) model.\n\n[image:rId169]\n\n[Image:rId169] The image shows the ECMiner data mining software's interface, displaying a linear regression model with coefficients c, A1, A2, ..., Ap, B1, B2, and an error term ε. The model predicts y based on x variables, where each coefficient represents the impact of a specific variable on the",
    "Context_id": "4장_v3_sanitized::chunk_0093",
    "Is_image": true,
    "Image_ids": [
      "rId161",
      "rId162",
      "rId163",
      "rId164",
      "rId168",
      "rId165",
      "rId166",
      "rId167",
      "rId169"
    ],
    "Is_table": true,
    "Table_ids": [
      "t841"
    ],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to How to run.\n\n[Analyze] – [Time Series Analysis] – [Time Series Models] – [VAR]\nOn the main screen, enter the basic information required for VAR analysis. When selecting Dependent Variable (Response Variable) and Independent Variable (Explanatory Variable), you can select multiple variables as dependent variables, and you may or may not select Independent Variable. When entering the degree of a dependent variable and the degree of an independent variable, enter the starting and ending degrees.\n[image:rId170]\n[image:rId171]\nIf you select default for Dependent Variable Lag Selection, the order set on the main screen is set. If you do not select default option, user can enter Specific Lag. (At this time, the order is divided by space.)\nIf you select default for Independent Variable Lag Selection, the order set on the Main screen is set. If you do not select default option, user can enter Specific Lag. (At this time, the order is divided by space.)\nIn the forecast-related options, you can select the data to be used for modeling and perform N step ahead forecast by selecting a specific step ahead when selecting to perform model verification. ECMiner™ performs N step ahead forecast starting immediately after the modeling data. Through this, analysts can assess whether the model created through modeling is useful for future predictions.\n\n[Image:rId170] The image shows the \"TimeSeries Sample\" window in ECMiner, a data mining software tool. It is used for analyzing time series data, specifically focusing on forecasting temperature based on historical data. The user interface allows selection of dependent and independent variables, including target, predicted temperature, real temperature, day, day coefficient\n\n[Image:rId171] The image is a screenshot of the VAR Option window in ECMiner, a data mining software tool. It allows users to select dependent and independent variable lags for forecasting models, with options to specify default settings or custom lags. The user can also choose the number of steps ahead for the forecast, set up model",
    "Context_id": "4장_v3_sanitized::chunk_0094",
    "Is_image": true,
    "Image_ids": [
      "rId170",
      "rId171"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to Results.\n\nModel Report\n\nGeneral Info: Shows basic information about time series data.\n\nModel Info: Provides parameters, statistics, and forecast results obtained through VAR analysis.\n\nResidual Chart: Shows Residual Autocorrelation Function, Residual Partial Autocorrelation Function.\n\n[image:rId172]\n\n[Image:rId172] The image shows the Time Series Analysis VAR Model Information page in ECMiner, displaying coefficients for a time series model with Target as the dependent variable and Predicted Temp as an independent variable. The model includes constant, Target(1), and Predicted Temp(0) and (1) terms, with statistical measures like\n\nPlot\n\nVisually displays data obtained through VAR analysis. Shows Time Series Plot and Residual Plot (Histogram, Normal Probability Plot, Residual vs. Order, Residual vs. Fitted Values).\n\nBelow is an example of a Time Series Plot. You can see time series data, fitted values, and upper and lower limits of fitted values at a glance.\n\n[image:rId173]\n\n[Image:rId173] The image shows an analysis using ECMiner software for time series data, focusing on forecasting temperature trends with a model that includes predicted and real temperatures as variables. The graph displays historical temperature data points over time, with different colored lines representing various models or forecasts, highlighting the variability and patterns in temperature fluctuations.\n\nStatistics\n\nThe statistics obtained through VAR analysis can be seen in the table. In addition, it also provides the function to save tables.\n\n(8) ARMAX\nOverview\nARMAX stands for ARMA with Exogenous Variable and is a model that adds Exogenous Variable to the already mentioned ARMA model. This model can be described as:\n\n[image:rId174]\n\n[Image:rId174] The image shows an interface for ECMiner, a data mining tool, where users can input parameters to perform clustering analysis on data. The main purpose is to analyze and group similar data points into clusters based on their features. The content includes user inputs such as feature vectors (x1, x2, ..., xm)\n\nBoth Parameter Estimation and Forecasting are the same as existing ARMA methods. All processes can be said to be the same if you just replace the existing [image:rId175] or [image:rId176] with [image:rId177] or [image:rId178]. This can be said to be a model that helps to better explain time series that cannot be explained simply with ARMA alone using Exogenous Variable.\n\n[Image:rId178] The image shows the ECMiner software's interface for data mining, specifically displaying a linear regression model with multiple variables. The equation represents a linear combination of coefficients (β) multiplied by corresponding variable values (x), minus an intercept (μ). This is used to predict or analyze relationships between variables in data mining tasks.\n\n[Image:rId175] The image shows the ECMiner software interface, which is used for data mining and analysis. It displays various options and settings for configuring the mining process, including parameters like the number of threads, data sources, and output formats. The main purpose is to automate the extraction of patterns and insights from large datasets efficiently.\n\n[Image:rId176] The image shows the ECMiner software interface, specifically the \"Data Mining\" tab. It displays a dataset with columns for \"Feature1,\" \"Feature2,\" and \"Label.\" The goal is to analyze and mine patterns in the data, likely for classification or clustering purposes.\n\n[Image:rId177] The image shows the ECMiner software's interface for data mining, specifically focusing on the extraction of patterns from datasets. It displays a matrix with rows representing different variables (x1 to xk) and columns representing extracted features (y, β1, ..., βm). The goal is to identify relationships between these variables",
    "Context_id": "4장_v3_sanitized::chunk_0095",
    "Is_image": true,
    "Image_ids": [
      "rId172",
      "rId173",
      "rId174",
      "rId175",
      "rId176",
      "rId177",
      "rId178"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to How to run.\n\n[Analyze] – [Time Series Analysis] – [Time Series Models] – [ARMAX]\n[image:rId179]\nOn main screen, you can enter basic information required for ARMAX analysis. When selecting Dependent Variable (Response Variable) and Independent Variable (Explanatory Variable), the independent variable may not be selected. In this case, you will get the same results as traditional ARIMA. Analysts can add seasonality or differences as in traditional ARIMA. ARMAX analysis can be performed through various order settings displayed on the main screen.\n[image:rId180]\nIn addition, you can make more advanced settings through the ARMAX Options window. If you want to enter the AR order as the order specified by the analyst, uncheck the Default check box. Then, you can specify the AR order in space units. If you want to enter the MA order as the order specified by the analyst, uncheck the Default check box. Then you can specify the MA degree in space units.\nAs to which method to use to estimate the parameters of ARMAX, you can choose between Maximum Likelihood and Conditional Least Square. Levenberg Marquardt and Quasi Newton are provided as optimization methods. By using these two methods, users can use the better parameters of the two.\nIf you want to change the parameters used for optimization, set the Parameter Change Status as ‘Change’. This allows you to decide whether to optimize further or not.\nForecast-related Options allow you to select the data used for modeling and decide whether to perform model validation. When ‘Perform Model Validation’ is checked, the predicted values are calculated from the modeling data. Through this, you can gauge how accurate the model obtained through modeling is.\nThe Initial Value Selection Method is intended to compensate for the limitations of Nonlinear Optimization. It helps to find the optimal solution by setting various initial values.\n\n[Image:rId179] The image shows the ARMAX Variable Selection window in ECMiner, used for time series analysis to model temperature data with an ARIMA model, including parameters like AR order, MA order, and seasonal components.\n\n[Image:rId180] The ARMAX Options window in ECMiner is used for configuring parameters to perform ARIMA modeling, including selecting AR and MA lags, choosing an optimization method, setting parameter change status, specifying forecast-related options, and initializing value selection methods.",
    "Context_id": "4장_v3_sanitized::chunk_0096",
    "Is_image": true,
    "Image_ids": [
      "rId179",
      "rId180"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to Results.\n\nModel Report\n\nGeneral Info: Shows basic information about time series data.\n\nModel Info: Provides parameters, statistics, and forecast results obtained through ARMAX analysis.\n\nResidual Chart: Shows Residual Autocorrelation Function, Residual Partial Autocorrelation Function.\n\n[image:rId181]\n\n[Image:rId181] The image shows the ARMAX model selection and estimation process in ECMiner, focusing on time series analysis for temperature forecasting. It displays parameter estimates, standard errors, t-values, and p-values for AR(1) and Target variables, along with model summary statistics like maximum likelihood, residual sum of squares, and variance\n\nPlot\n\nVisually displays data obtained through ARMAX analysis. Shows Time Series Plot and Residual Plot (Histogram, Normal Probability Plot, Residual vs. Order, Residual vs. Fitted Values).\n\nBelow is an example of a Time Series Plot. You can see time series data, fitted values, and upper and lower limits of fitted values at a glance.\n\n[image:rId182]\n\n[Image:rId182] The screenshot shows an ARMAX model analysis in ECMiner, analyzing temperature data with seasonal effects. The plot displays time series data, forecasts, and confidence intervals for temperature predictions.\n\nStatistics\n\nThe statistics obtained through VAR analysis can be seen in the table. In addition, it also provides the function to save tables.",
    "Context_id": "4장_v3_sanitized::chunk_0097",
    "Is_image": true,
    "Image_ids": [
      "rId181",
      "rId182"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to Time Series Test.\n\n(1) Unit Root Test",
    "Context_id": "4장_v3_sanitized::chunk_0098",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "4.3.6.2 Time Series Test"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to Overview.\n\nNon-stationary time series have a characteristic root of 1 when expressed as an autoregressive model. That is, it has a unit root. The Time Series Test menu supports KPSS (Kwiatkowski & Phillips & Schmidt & Shin) test and ADF (Augmented Dickey-Fuller) test. The null hypothesis of the ADF test is that a unit root exists in the variable, and the null hypothesis of the KPSS test is that the unit root does not exist in the variable. Decide whether to accept or reject the null hypothesis through test statistics (TAU) and significance probability (p-value).",
    "Context_id": "4장_v3_sanitized::chunk_0099",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "Overview"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to How to use.\n\n[Analyze] – [Time Series Analysis] – [Time Series Test] – [Unit Root Test]\nIn the window, select which test method to use, select/enter the parameters required for each method, and then select the variable to be tested. Click the OK button and the Time Series Test will be performed.\n[image:rId183]\n\n[Image:rId183] The Unit Root Test window in ECMiner software is used to analyze time series data for stationarity, with the Target variable being tested using the Augmented Dickey-Fuller (ADF) method, set to Mu type and with a Lag of 3.\n\nADF (Augmented Dickey-Fuller) Test\n\nTime series data can be represented in different forms depending on whether constants and deterministic trends are included. The selection type of ADF Test must be entered according to the type of time series data to be tested.\n\nThe test model for the case that does not include constants and deterministic trends (Type = none) is as follows.\n\n[image:rId184]\n\n[Image:rId184] The image shows the output of an ECMiner data mining algorithm, where yt represents the current prediction, yt-1 is the previous prediction, S is the sum of all previous predictions, and et is the error term. The algorithm aims to predict future values based on historical data.\n\nThe test model when only constants are included (Type = Drift) can be expressed as follows.\n\n[image:rId185]\n\n[Image:rId185] The image shows a screenshot of an ECMiner data mining software interface, displaying a linear regression model with coefficients \\( y_i = \\alpha + \\gamma_i y_{i-1} + \\frac{\\epsilon_i}{\\sum_j \\gamma_j y_{j-1}} \\). This equation represents a recursive\n\nThe test model when including both constant and deterministic trends (Type = Trend) is as follows.\n\n[image:rId186]\n\n[Image:rId186] The image shows the output of an ECMiner data mining algorithm, where yt is the predicted value, α is the intercept, β is the slope, vt is the error term, yt-1 is the previous prediction, and εt is the random noise. The algorithm uses historical data to predict future values based on\n\nLag is the order of the first autoregressive term included in the regression equation of the test model, and is the p value of the above regression equation. So you can get the correct result, only when the Lag value is greater than 1.\n\nResults\n\n[image:rId187]\n\n[Image:rId187] The image shows the results of an Augmented Dickey-Fuller Test in ECMiner, indicating that the time series is non-stationary with a critical value of -1.718 for tau, suggesting it may be integrated of order 1 (I(1)). The regression analysis reveals significant coefficients\n\nIt provides statistics such as Test-statistics, Critical value, Coefficient, Multiple R-square, Adjusted R-square, F-statistics, p-value, etc. according to each test method. In Coefficient, Intercept is a constant term, tt is a deterministic trend, z.lag.1 is y, and z.diff.lag1 is the value of the first difference of y.\n\nKPSS(Kwiatkowski & Phillips & Schmidt & Shin) Test\n\nThe formula for calculating the test statistics value of KPSS is as follows.\n\n[image:rId188] [image:rId189]\n\n[Image:rId189]\n\n[Image:rId188]\n\nWhen a time series is expressed as a regression equation of random work + deterministic trend + stationary error like, then. (et , t = 1, 2, … , N, are the residuals ) X t = r t + βt= ε t S i = j=1 t e j\n\nIf Type is entered as Mu, set residuals as 'residual = y – mean(y)', and if Type is entered as Tau, uses residuals from the result of linear regression which has y as dependent variable, and time trend as independent variable.\n\nResults\n\n[image:rId190]\n\n[Image:rId190] The image shows the results of a KPSS (Kwiatkowski, Phillips, Schmidt, and Shin) test for unit root in time series data using ECMiner software. The test statistic value is 0.874, which is compared to critical values at different significance levels (1%, 2.\n\nThis test method provides test statistics and critical value values for each significance level (1%, 2.5%, 5%, 10%).\n\n(2) Granger Causality",
    "Context_id": "4장_v3_sanitized::chunk_0100",
    "Is_image": true,
    "Image_ids": [
      "rId183",
      "rId184",
      "rId185",
      "rId186",
      "rId187",
      "rId188",
      "rId189",
      "rId190"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "How to use"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to Overview.\n\nThe Granger causality test is a statistical hypothesis test that tests whether the one time series is useful for predicting the other time series. Through t-test and F-test, we test whether Independent Variable provides statistically significant information about the future of Dependent Variable.",
    "Context_id": "4장_v3_sanitized::chunk_0101",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "Overview"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to How to run.\n\n[Analyze] – [Time Series Analysis] – [Time Series Test] – [Granger Causality]\nIn the window select Dependent Variable and Independent Variable. If you check “Save Significant Results to File”, you can save the test result, a list of independent variables whose p-value is less than the value entered by the user, and the p-value value as a text file. Click the View Results button to perform Granger causality.\n[image:rId191]\n\n[Image:rId191] The image is a screenshot of the Granger Causality window in ECMiner, a data mining software tool. It shows options for selecting dependent and independent variables to analyze the causal relationships between them. The user can choose which variable is the target and which is the predictor, with additional options for saving results and setting",
    "Context_id": "4장_v3_sanitized::chunk_0102",
    "Is_image": true,
    "Image_ids": [
      "rId191"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to Results.\n\n[image:rId192]\nProvides F-Statistics value and p-Value, which are causality test results.\n(3) Cointegration Test\n\n[Image:rId192] The Granger Causality analysis in ECMiner shows that \"Real Temp\" is a significant independent variable with an F-Statistic of 20,343 and a P-Value of 0, indicating a strong causal relationship between temperature and other variables.",
    "Context_id": "4장_v3_sanitized::chunk_0103",
    "Is_image": true,
    "Image_ids": [
      "rId192"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to Overview.\n\nWhen two or more time series are individually integrated, but some of their linear combinations are low order, these time series are said to be cointegrated. Cointegration Test tests how cointegrated two or more time series are. There are methods such as The Engle-Granger two-step method, The Johansen’s procedure, and Phillips-Ouliaris Cointegration Test, and the Johansen’s procedure is used in the Cointegration Test menu.",
    "Context_id": "4장_v3_sanitized::chunk_0104",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "Overview"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to How to run.\n\n[Analyze] – [Time Series Analysis] – [Time Series Test] – [Cointegration Test]\nSelect the dependent and independent variables in the window. In the Type menu, you can select None, Constant, or Trend.\n[image:rId193]\n\n[Image:rId193] The Cointegration Test window in ECMiner is used to analyze the relationship between the Target variable and other variables like Predicted Temp, Real Temp, Day, and Days. The user has selected the Target as the dependent variable and specified a lag of 2 for the analysis.",
    "Context_id": "4장_v3_sanitized::chunk_0105",
    "Is_image": true,
    "Image_ids": [
      "rId193"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to Results.\n\n[image:rId194]\nProvides the value of test statistics, which is the result of the cointegration test.\n(4) ARCH Test\n\n[Image:rId194] The image shows the results of an Augmented Dickey-Fuller Test in ECMiner, indicating that the null hypothesis of no unit root is rejected at the 1% significance level, suggesting stationarity in the time series data.",
    "Context_id": "4장_v3_sanitized::chunk_0106",
    "Is_image": true,
    "Image_ids": [
      "rId194"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to Overview.\n\nThe ARCH model is a heteroskedastic conditional autoregressive model for predicting the volatility of a time series that changes over time. The ARCH test is used to determine whether the current variance can be predicted by the past variance.",
    "Context_id": "4장_v3_sanitized::chunk_0107",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "Overview"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to How to run.\n\n[Analyze] – [Time Series Analysis] – [Time Series Test] – [ARCH Test]\nSelect the dependent and independent variables in the window. Enter the maximum disparity value. Arch Test is performed by clicking the View Results button.\n[image:rId195]\n\n[Image:rId195] The ARCH Test window in ECMiner is used to analyze the ARCH (Autoregressive Conditional Heteroskedasticity) model, focusing on the relationship between the dependent variable (Target) and independent variables like Predicted Temp and Real Temp over a maximum lag of 4 periods.",
    "Context_id": "4장_v3_sanitized::chunk_0108",
    "Is_image": true,
    "Image_ids": [
      "rId195"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to Results.\n\n[image:rId196]\nTest statistics of Arch test are provided.\n\n[Image:rId196] The ARCH Test screen in ECMiner shows results for an ARCH model with order 4, indicating significant ARCH effects at various lags. The test statistic is highly significant, rejecting the null hypothesis that no ARCH effect exists.",
    "Context_id": "4장_v3_sanitized::chunk_0109",
    "Is_image": true,
    "Image_ids": [
      "rId196"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to Time Series Correlation.\n\n(1) Cross-Correlation",
    "Context_id": "4장_v3_sanitized::chunk_0110",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "4.3.6.3 Time Series Correlation"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to Overview.\n\nCross-Correlation is an indicator that measures the similarity between two time series. Cross-Correlation is mainly used to discover short, known features in long-duration signals. When there are two time series X and Y, the k-time difference cross-correlation coefficient [image:rId197] between the two-time series is calculated as follows.\n\n[Image:rId197] The image shows the ECMiner software interface, which is used for data mining tasks. It displays various options and settings related to mining algorithms, such as \"K-Means Clustering,\" \"Association Rules,\" and \"Feature Selection.\" The user can select these options to analyze and process data efficiently.\n\n[image:rId198]\n\n[Image:rId198] The image shows the calculation of the Pearson correlation coefficient (r) between two variables X and Y using the formula r = Σ(Xi - X̄)(Yi + k - Ȳ) / √(Σ(Xi - X̄)²Σ(Yi - Ȳ)²",
    "Context_id": "4장_v3_sanitized::chunk_0111",
    "Is_image": true,
    "Image_ids": [
      "rId197",
      "rId198"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "Overview"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to How to run.\n\n[Analyze] – [Time Series Analysis] – [Time Series Correlation] – [Cross-Correlation]\nOpen the Settings dialog from the menu “File>Settings”. Select dependent and independent variables in the window. Cross-Correlation is executed when you click the OK button.\n[image:rId199]\n\n[Image:rId199] The image shows the settings window for configuring a time series analysis in ECMiner, with the user setting the lag count to 10, selecting \"Target\" as the dependent variable, and specifying \"Predicted Temp,\" \"Real Temp,\" \"Day,\" \"Day Coeff,\" \"Days,\" and \"Temp\"",
    "Context_id": "4장_v3_sanitized::chunk_0112",
    "Is_image": true,
    "Image_ids": [
      "rId199"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to Results.\n\n[image:rId200]\nProvides the Cross-Correlation coefficient between Independent Variable and Dependent Variable at the corresponding time difference.\n(2) Autocorrelation, Partial Autocorrelation\n\n[Image:rId200] The image shows the Cross-Correlation function for Predicted Temp in ECMiner, displaying lag values and their corresponding cross-correlation coefficients, indicating strong negative correlations between predicted temperature and various lags.",
    "Context_id": "4장_v3_sanitized::chunk_0113",
    "Is_image": true,
    "Image_ids": [
      "rId200"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to Overview.\n\nAutocorrelation is a measure that shows how the value of current time series data is correlated with past data. The higher autocorrelation values mean the higher the possibility that predict your current value through your past data.\nTo explain the partial autocorrelation, we will use the following model as an example.\n\n[image:rId201]\n\n[Image:rId201] The image shows the ECMiner software's interface, specifically displaying the z_t variable in a time series analysis context. It represents a random variable with a mean of zero and variance σ^2, generated independently and identically distributed (iid) from a normal distribution N(0, σ^2). This is used\n\nIf you calculate the second-order autocorrelation coefficient from the above time series model, you will get a significant value and the analyst may think that the autocorrelation coefficient in the second order is significant because the above time series was created in AR(2), or because it was created in AR(3). Therefore, in addition to autocorrelation, the concept of partial autocorrelation is needed. For example, if you want to find the second-order partial autocorrelation coefficient, you find the correlation coefficient after excluding the influence of the first-order. In this case, the value of the second-order autocorrelation coefficient may be high, but the value of the second-order partial autocorrelation function will be small.",
    "Context_id": "4장_v3_sanitized::chunk_0114",
    "Is_image": true,
    "Image_ids": [
      "rId201"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "Overview"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to How to run.\n\n[Analyze] – [Time Series Analysis] – [Time Series Correlation] – [Autocorrelation, Partial Autocorrelation]\nSelect the type of correlation function in the window. The analyst can select the autocorrelation function or partial autocorrelation function and select the variable to be analyzed along with it. By determining the maximum number of lags, the analyst can determine how much lag the correlation function will be obtained.",
    "Context_id": "4장_v3_sanitized::chunk_0115",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Time Series Analysis, with a detailed reference to Results.\n\n[image:rId202]\nAbove is an example of an autocorrelation function. The autocorrelation function shows the correlation coefficient and t-statistic as well as the Ljung-Box Q-test statistic. The Q test statistic value is used to test the hypothesis of whether data are independently distributed. Independently distributed data means that any correlation found in the data was created by random sampling.\n[image:rId203] Above is an example of partial autocorrelation function.\n\n[Image:rId202] The image shows an autocorrelation function plot in ECMiner, analyzing the correlation between different lags of the target variable. The graph indicates strong positive autocorrelation up to lag 12, with coefficients peaking at around 0.97 for lags 1-3. The table on the\n\n[Image:rId203] The image shows the Partial Autocorrelation Function (PACF) plot in ECMiner, analyzing the relationship between variables over time. The PACF plot indicates that the target variable has a strong positive correlation at lag 1, with subsequent lags showing diminishing correlations. The table on the right provides detailed statistics",
    "Context_id": "4장_v3_sanitized::chunk_0116",
    "Is_image": true,
    "Image_ids": [
      "rId202",
      "rId203"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.6 Time Series Analysis",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, focusing on T able.",
    "Context_id": "4장_v3_sanitized::chunk_0117",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.7 T able"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection T able, with a detailed reference to Frequency Table.\n\nFrequency Table shows how often each distinct value occurs in a dataset.",
    "Context_id": "4장_v3_sanitized::chunk_0118",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.7 T able",
      "4.3.7.1 Frequency Table"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection T able, with a detailed reference to How to run.\n\n[Analyze] – [Table] – [Frequency Table]\n[image:rId204]\n\n[Image:rId204] The image shows the \"Frequency Table\" window in ECMiner, where users can select variables for analysis by dragging them into the \"Analysis Variable\" list. The goal is to perform frequency analysis on specified variables A4 and A9.",
    "Context_id": "4장_v3_sanitized::chunk_0119",
    "Is_image": true,
    "Image_ids": [
      "rId204"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.7 T able",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection T able, with a detailed reference to Results.\n\n[image:rId205]\n\n[Image:rId205] The image shows frequency statistics tables for two datasets, A2 and A3, with columns for discrete values, frequency, percentage, cumulative frequency, and cumulative percentage. The tables provide insights into the distribution of discrete categories in each dataset.",
    "Context_id": "4장_v3_sanitized::chunk_0120",
    "Is_image": true,
    "Image_ids": [
      "rId205"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.7 T able",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection T able, with a detailed reference to Cross Table.\n\nCross table is for two variables.",
    "Context_id": "4장_v3_sanitized::chunk_0121",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.7 T able",
      "4.3.7.2 Cross Table"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection T able, with a detailed reference to How to run.\n\n[Analyze] – [Table] – [Cross Table]\n[image:rId206]\nPercentage options are row percentage, column percentage and total percentage.\nStatistics options measure the strength of the association between row and column variables based on chi-square test, and provide Conti n gency coefficient and Phi and Cramer’s V. Both statistics have values between 0 and 1, with the closer to 1 indicating a stronger association.\n\n[Image:rId206] The image shows a Cross Table in ECMiner, used to analyze relationships between categorical variables. It displays \"churn_status\" as the row variable, with other variables like A1 through A9 in the column. The statistics selected include Contingency coefficient and Phi and Cramer's V, indicating an analysis of",
    "Context_id": "4장_v3_sanitized::chunk_0122",
    "Is_image": true,
    "Image_ids": [
      "rId206"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.7 T able",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection T able, with a detailed reference to Results.\n\n[image:rId207]\n\n[Image:rId207] The image shows a cross-tabulation analysis in ECMiner, comparing churn status (0: not churned, 1: churned) with another variable (A9). It reveals that 98.28% of non-churners have A9 category A, while 99.91",
    "Context_id": "4장_v3_sanitized::chunk_0123",
    "Is_image": true,
    "Image_ids": [
      "rId207"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.7 T able",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection T able, with a detailed reference to Univariate Chi-Square Test.\n\nUnivariate Chi-Square Test checks if the observed data fits a specified distribution with expected frequencies or ratios.",
    "Context_id": "4장_v3_sanitized::chunk_0124",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.7 T able",
      "4.3.7.3 Univariate Chi-Square Test"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection T able, with a detailed reference to How to run.\n\n[Analyze] – [Table] – [Univariate Chi-Square Test]\nSelect the Test variable (categorical variable) and frequency variable, and select Equal Ratios or Specific Ratio. You can select a chart of observed and expected distribution.\n[image:rId208]\nSpecific Ratio refers to the frequency by category, where you enter the ratios directly. You must enter a ratio for each category, separated by ‘;’.\n[image:rId209]\n\n[Image:rId208] The image is a screenshot of the Chi-Square Distribution Goodness-of-Fit Test window in ECMiner, used to evaluate if observed frequencies match expected frequencies for a specified variable (region) with an option to select either equal ratios or specific ratios. The user can choose to display a chart comparing observed and expected distributions\n\n[Image:rId209] The image shows a Chi-Square Goodness-of-Fit Test results window in ECMiner, displaying frequency counts for different regions (London, Midlands & East Anglia, Scotland, South East, South West, The North, Wales). It's used to assess if the observed frequencies match expected values across these categories.",
    "Context_id": "4장_v3_sanitized::chunk_0125",
    "Is_image": true,
    "Image_ids": [
      "rId208",
      "rId209"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.7 T able",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection T able, with a detailed reference to Results.\n\nThe results of the chi-square goodness-of-fit test appear as follows:\nThe contribution to the test ratio, expected value, and chi-square test statistic for each category is displayed, and the p-value is used to test the data's fit to the expected frequency.\n[image:rId210]\nSelect the distribution chart tab in the results window to view the observed and expected values distribution chart\n[image:rId211]\n\n[Image:rId210] The image shows a Chi-Square Goodness-of-Fit Test conducted on a dataset with 1691 observations, testing the distribution of regions in the UK. The test evaluates whether the observed frequencies match expected frequencies across different regions like London, Midlands & East Anglia, Scotland, etc., concluding that the observed\n\n[Image:rId211] The Chi-Square Goodness-of-Fit Test in ECMiner compares observed (red bars) and expected (green bars) values across regions like London, Scotland, South East, etc., to assess if the distribution is consistent with a null hypothesis.",
    "Context_id": "4장_v3_sanitized::chunk_0126",
    "Is_image": true,
    "Image_ids": [
      "rId210",
      "rId211"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.7 T able",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection T able, with a detailed reference to Independence Test (Chi-Square Test).\n\nThe Independence Test – Chi-Square Test is to test whether two categorical variables are independent.",
    "Context_id": "4장_v3_sanitized::chunk_0127",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.7 T able",
      "4.3.7.4 Independence Test (Chi-Square Test)"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection T able, with a detailed reference to How to run.\n\n[Analyze] – [Table] – [Independence Test]\nSelect two variables to analyze\n[image:rId212]\n\n[Image:rId212] The image is a screenshot of the Chi-Square Test interface in ECMiner, a data mining software tool. It displays variables for row and column selection, with options to specify significance levels (0.1, 0.05, 0.025) and whether to consider null values. The",
    "Context_id": "4장_v3_sanitized::chunk_0128",
    "Is_image": true,
    "Image_ids": [
      "rId212"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.7 T able",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection T able, with a detailed reference to Results.\n\n[image:rId213]\n\n[Image:rId213] The image shows a Chi-Square Test result comparing the distribution of smokers among males and females in a dataset. It indicates that there is no significant association between sex and smoking status, with p-values close to 1.",
    "Context_id": "4장_v3_sanitized::chunk_0129",
    "Is_image": true,
    "Image_ids": [
      "rId213"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.7 T able",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, focusing on Probability Distribution.",
    "Context_id": "4장_v3_sanitized::chunk_0130",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.8 Probability Distribution"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Probability Distribution, with a detailed reference to Parameter Estimation.\n\nThere are several methods to estimate the parameters of a probability distribution, including Method of Moment and Maximum Likelihood. ECMiner™ optimizes and estimates the parameters of a probability distribution using the Maximum Likelihood method based on the given data, and it provides confidence intervals for the estimated parameters to indicate their reliability.",
    "Context_id": "4장_v3_sanitized::chunk_0131",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.8 Probability Distribution",
      "4.3.8.1 Parameter Estimation"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Probability Distribution, with a detailed reference to How to run.\n\n[Analyze] – [Probability Distribution] – [Parameter Estimation]\nThere are 12 distributions. The user can select the distribution to fit the data, specify which field contains the data, and choose the desired confidence level for the estimation. After making these selections, clicking \"View Results\" will display the output",
    "Context_id": "4장_v3_sanitized::chunk_0132",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.8 Probability Distribution",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Probability Distribution, with a detailed reference to (1) Beta Distribution.\n\nEstimation method\n\nThe pdf of the Beta Distribution is given as following:\n\nf (x | α, β)= Γ (α + β) Γ (α) Γ (β) x α -1 (1-x) β -1\n\n0≤ x ≤1, α >0, β >0\n\nThe Likelihood Function for this is as follows:\n\nL(x i |α,β)= i=1 n Γ(α+β) Γ(α)Γ(β) x i α-1 (1-x i) β-1\n\nThe value of and [image:rId214] that maximize this function are known as the Maximum Likelihood Estimators. To simplify the above equation by taking the logarithm, α β\n\n[Image:rId214] The image shows the ECMiner software interface, which is used for data mining and analysis. It displays various options and settings for configuring the mining process, including parameters like alpha and beta, which are likely related to the mining algorithm's parameters. The main purpose is to facilitate the extraction of meaningful patterns and insights from large\n\nln L (x i | α, β) = n ln Γ α + β -n ln Γ α -n ln Γ β + α -1 i = 1 n ln x i +(β -1) i = 1 n ln (1 -x i)\n\nThere are several methods to maximize the above equation. ECMiner™ employs Nelder and Mead's Simplex method to maximize the Likelihood Function.\n\nCaution: All data used in Beta Distribution must be between 0 and 1.\n\nExample\n\n[image:rId215]\n\n[Image:rId215] The image shows the Probability Distribution window in ECMiner, where users can select a distribution type (e.g., Beta) for analysis. The current selection is Beta, with confidence levels set to 95%. The output displays estimated parameters Alpha and Beta along with their respective confidence intervals.",
    "Context_id": "4장_v3_sanitized::chunk_0133",
    "Is_image": true,
    "Image_ids": [
      "rId214",
      "rId215"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.8 Probability Distribution",
      "(1) Beta Distribution"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Probability Distribution, with a detailed reference to (2) Binomial Distribution.\n\nEstimation method\n\nThe pmf of the Binomial Distribution is given as following:\n\nf(x|n,p)= n x p x (1-p) n-x\n\nThe Likelihood Function for this is as follows:\n\nL(x i |n,p)= i=1 n n x i p x i (1-p) n-x i\n\nThe value of and [image:rId214] that maximize this function are known as the Maximum Likelihood Estimators. To simplify the above equation by taking the logarithm, n p\n\nln L (x i | n, p) = ln n x i + x i ln p +(n -x i) ln (1 -p)\n\nTake the partial derivative of the above equation and set it equal to zero to maximize the likelihood function.\n\n∂ ∂p ln L (x i | n, p) = x i p -n -x i1 -p = 0\n\nThe maximum likelihood estimate is as follows.\n\np = x i n\n\nExample\n\n[image:rId216]\n\n[Image:rId216] The image shows the Probability Distribution section in ECMiner, where users can select different distribution types like Binomial, Beta, etc., for analyzing data. The current selection is \"Binomial Distribution,\" with fields like \"D_FIELD1\" selected and confidence levels set to 90%. The output provides an estimate of",
    "Context_id": "4장_v3_sanitized::chunk_0134",
    "Is_image": true,
    "Image_ids": [
      "rId214",
      "rId216"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.8 Probability Distribution",
      "(2) Binomial Distribution"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Probability Distribution, with a detailed reference to (4) Exponential Distribution.\n\nEstimation method\n\npdf of the Exponential Distribution is given as follows:\n\nf(x|λ)=λ e -λx\n\nThe corresponding Likelihood Function is:\n\nL(λ)= i=1 n λ e -λ x i\n\nThe value of [image:rId214] that maximize this function are known as the Maximum Likelihood Estimators. To simplify the above equation by taking the logarithm, λ\n\nln L (λ) = i = 1 n ln λ -λ i = 1 n x i\n\nTake the partial derivative of the above equation and set it equal to zero to maximize the likelihood function.\n\n∂ ∂λ ln L (λ) = n λ -i = 1 n x i = 0\n\nLooking at the above, the maximum likelihood estimate is as follows.\n\nλ = n i = 1 n x i\n\nExample\n\n[image:rId217]\n\n[Image:rId217] The image shows the Probability Distribution window in ECMiner, where users can select different distributions like Beta, Binomial, Exponential, etc., to analyze data. The current selection is \"Exponential Distribution,\" with input field A5 selected and a confidence level set at 90%. The output displays an estimate of",
    "Context_id": "4장_v3_sanitized::chunk_0135",
    "Is_image": true,
    "Image_ids": [
      "rId214",
      "rId217"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.8 Probability Distribution",
      "(4) Exponential Distribution"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Probability Distribution, with a detailed reference to (5) Gamma Distribution.\n\nEstimation method\n\nThe pdf of the Gamma Distribution is as follows:\n\nf(x|α,β)= 1 β α Γ(α) x α-1 e -x β\n\nx>0, α>0, and β>0\n\nThe Likelihood Function for this is as follows:\n\nL(x i |α,β)= i=1 n1 β α Γ(α) x i α-1 e -x i β\n\nThe value of and [image:rId214] that maximize this function are known as the Maximum Likelihood Estimators. To simplify the above equation by taking the logarithm, α β\n\nln L (x i | α, β) =-nα ln β -n ln Γ α +(α -1) i = 1 n ln x i -1 β i = 1 n x i\n\nTake the partial derivative of the above equation and set it equal to zero to maximize the likelihood function.\n\n∂ ∂α ln L (x i | α, β) =-n ln β + i = 1 n ln x i -n ∂ ln Γ α ∂α = 0\n\nBy using Newton Raphson's method:\n\nα = α -f α f'(α)\n\nwhere f'α =-n ∂ 2 ln Γ α ∂α + n α\n\n∂ ∂β ln L (x i | α, β) =-nα β + 1 β2 i = 1 n x i = 0\n\nβ = x α\n\nExample\n\n[image:rId218]\n\n[Image:rId218] The image shows the Probability Distribution section of ECMiner, where users can select different distributions like Beta, Binomial, Gamma, etc., to analyze data. The current selection is Gamma Distribution. Users can choose a confidence level (90%, 95%, or 99%) and view the estimated parameters Alpha",
    "Context_id": "4장_v3_sanitized::chunk_0136",
    "Is_image": true,
    "Image_ids": [
      "rId214",
      "rId218"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.8 Probability Distribution",
      "(5) Gamma Distribution"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Probability Distribution, with a detailed reference to (8) Normal Distribution.\n\nEstimation method\n\nThe pdf of Normal Distribution is given as following:\n\nf(x|μ, σ2)= 12 π σ e - (x-μ) 22 σ2\n\nThe corresponding Likelihood Function is:\n\nL(x i |μ, σ2)= i=1 n12 π σ e - (x-μ) 2 σ2\n\nThe value of and [image:rId214] that maximize this function are known as the Maximum Likelihood Estimators. To simplify the above equation by taking the logarithm, μ σ2\n\nln L (x i | μ, σ2) = n2 ln2 π -n2 ln σ2 -12 σ2 i = 1 n x i -μ2\n\nTake the partial derivative of the above equation and set it equal to zero to maximize the likelihood function.\n\n∂ ∂μ ln L (x i | μ, σ2) = 1 σ2 i = 1 n x i -μ2 = 0\n\nμ = 1 n i = 1 n x i\n\n∂ ∂ σ2 ln L (x i | μ, σ2) =-n2 σ2 + 12 σ4 i = 1 n x i -μ2 = 0\n\nσ2 = 1 n i = 1 n (x i -μ) 2\n\nHere is the quantile of Normal Distribution. X α α\n\nExample\n\n[image:rId219]\n\n[Image:rId219] The image shows the Probability Distribution window in ECMiner, where users can select a distribution type (e.g., Normal) to estimate parameters like mean (Mu) and standard deviation (Sigma) with specified confidence levels. The current selection is the Normal distribution, with estimated values for Mu and Sigma displayed alongside confidence intervals.",
    "Context_id": "4장_v3_sanitized::chunk_0137",
    "Is_image": true,
    "Image_ids": [
      "rId214",
      "rId219"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.8 Probability Distribution",
      "(8) Normal Distribution"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Probability Distribution, with a detailed reference to (9) Poisson Distribution.\n\nEstimation method\n\nThe pdf of Poisson Distribution is given as following:\n\nf(x|λ)= λ x x! e -λ\n\nThe corresponding Likelihood Function is:\n\nL(x i |λ)= i=1 n λ x x! e -λ\n\nThe value of [image:rId214] that maximize this function are known as the Maximum Likelihood Estimators. To simplify the above equation by taking the logarithm, λ\n\nln L x i λ = n = 1 n ln λ x i x i! e -λ\n\n=-nλ+ i=1 n x i ln λ -i=1 n x i!\n\nTake the partial derivative of the above equation and set it equal to zero to maximize the likelihood function.\n\n∂ ∂λ ln L x i λ =-n + 1 λ i = 1 n x i!= 0\n\nSolving this yields the following estimates:\n\nλ = 1 n i = 1 n x i\n\nExample\n\n[image:rId220]\n\n[Image:rId220] The image shows the Probability Distribution window in ECMiner, where users can select a distribution type (e.g., Poisson) for analyzing data fields like D_FIELD1 with specified confidence levels (90%, 95%, 99%). The output provides an estimate of Lambda and its confidence interval.",
    "Context_id": "4장_v3_sanitized::chunk_0138",
    "Is_image": true,
    "Image_ids": [
      "rId214",
      "rId220"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.8 Probability Distribution",
      "(9) Poisson Distribution"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Probability Distribution, with a detailed reference to (10) Continuous Uniform Distribution.\n\nEstimation method\n\nThe pdf of Continuous Uniform Distribution is given as follows:\n\nf x a,b = 1 b-a\n\nAnd the MLE for a and b are:\n\na = min x1, x2,.., x n\n\nb = max x1, x2,.., x n\n\nExample\n\n[image:rId221]\n\n[Image:rId221] The image shows the Probability Distribution section of ECMiner, where users can select different distributions like Beta, Binomial, etc., to estimate parameters such as Alpha and Beta for continuous uniform distribution. The confidence level is set to 95%, and the estimated values are displayed with their respective confidence intervals.",
    "Context_id": "4장_v3_sanitized::chunk_0139",
    "Is_image": true,
    "Image_ids": [
      "rId221"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.8 Probability Distribution",
      "(10) Continuous Uniform Distribution"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Probability Distribution, with a detailed reference to (11) Weibull distribution.\n\nEstimation method\n\nThe pdf of the Weibull distribution is given as follows:\n\nf(x|α ,β)= β α x α β -1 e -x α β\n\nx≥0,α>0,β>0\n\nhe corresponding Likelihood Function is:\n\nL(x i |α,β)= i=1 n β α x i α β -1 e -x i α β\n\nThe value of [image:rId214] that maximize this function are known as the Maximum Likelihood Estimators. To simplify the above equation by taking the logarithm, λ\n\nln L x α, β = n ln β -n ln α + β -1 i = 1 n ln x i -i = 1 n x i α β\n\nTake the partial derivative of the above equation and set it equal to zero to maximize the likelihood function.\n\n∂ ∂α ln L x i α, β =-n α + β α2 i = 1 n x i β e -x i α β = 0\n\n∂ ∂β ln L x i α, β = n β + i = 1 n ln x i -i = 1 n x i α β ln x i α = 0\n\nSolving this yields the following estimates:\n\nα = 1 n i = 1 n x i β1 β\n\nBy using Newton – Raphson method solved as β\n\nβ β + 1 = β β -f β β f'β β\n\nwhere f'β β = 1 n i=1 n ln x i i=1 n x i β -β i=1 n x i β ln x i -β i=1 n x i β (ln x i) 2\n\nExample\n\n[image:rId222]\n\n[Image:rId222] The image shows the Probability Distribution window in ECMiner, where users can select different distributions like Beta, Binomial, etc., to estimate parameters for a given field 'A' with specified confidence levels (90%, 95%, 99%). The output provides estimated values 'a' and 'b'",
    "Context_id": "4장_v3_sanitized::chunk_0140",
    "Is_image": true,
    "Image_ids": [
      "rId214",
      "rId222"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.8 Probability Distribution",
      "(11) Weibull distribution"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Probability Distribution, with a detailed reference to Individual Distribution Identification.\n\nTo check the distribution of data, one can apply various distributions and utilize the obtained Anderson-Darling statistic along with its P-value to determine the most similar distribution to the data.",
    "Context_id": "4장_v3_sanitized::chunk_0141",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.8 Probability Distribution",
      "4.3.8.2 Individual Distribution Identification"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Probability Distribution, with a detailed reference to How to run.\n\n[Analyze] – [Probability Distribution] – [Individual Distribution Identification]\n[image:rId223]\nFrom the variable list, select the variable for which distribution identification is desired (multiple selections are allowed), and then choose which distributions to apply from the distribution selection (multiple selections are allowed).\n\n[Image:rId223] The image is from the ECMiner software, showing the \"Individual Distribution Identification\" window where users can select variables for distribution identification. The left panel lists variable names with their types, while the right panel displays various distribution options like Extreme Value, Exponential, Gamma, Log-Normal, Normal, and Weibull",
    "Context_id": "4장_v3_sanitized::chunk_0142",
    "Is_image": true,
    "Image_ids": [
      "rId223"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.8 Probability Distribution",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Probability Distribution, with a detailed reference to Result.\n\nVariable information: Provides basic statistics of the selected variable(s).\n\nDistribution Parameter Estimation: Estimates the parameters of the selected distribution based on the relevant variable.\n\nTest statistic: Provides the Anderson-Darling statistic and P-value, indicating how well the variable fits the chosen distribution.\n\nNote: If the P-value exceeds 0.05, it can be concluded that variable adheres to the specified distribution.\n\n[image:rId224]\n\n[Image:rId224] The image shows the results of an individual distribution identification process using ECMiner software, analyzing variable A2 with various distributions like Extreme Value, Exponential, Gamma, and Log-Normal. The statistics indicate that the data fits the Extreme Value Distribution best, with a P-value less than 0.01, suggesting",
    "Context_id": "4장_v3_sanitized::chunk_0143",
    "Is_image": true,
    "Image_ids": [
      "rId224"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.8 Probability Distribution",
      "Result"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, focusing on Nonparametric Test.",
    "Context_id": "4장_v3_sanitized::chunk_0144",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.9 Nonparametric Test"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Nonparametric Test, with a detailed reference to One-Sample.\n\nA non-parametric one-sample test is used to evaluate whether the median of a sample differs from a hypothesized value. It does not assume a specific distribution and is useful when the data is not normally distributed. Our software supports the Wilcoxon signed-rank test, which takes into account the rank of values.",
    "Context_id": "4장_v3_sanitized::chunk_0145",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.9 Nonparametric Test",
      "4.3.9.1 One-Sample"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Nonparametric Test, with a detailed reference to How to run.\n\n[Analyze] – [Nonparametric Test]\n[image:rId225]\nSelect Analysis Variable and enter the hypothesized median. Set the Significance level. Choose one of two testing methods.\n\n[Image:rId225]",
    "Context_id": "4장_v3_sanitized::chunk_0146",
    "Is_image": true,
    "Image_ids": [
      "rId225"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.9 Nonparametric Test",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Nonparametric Test, with a detailed reference to Result.\n\n[image:rId226]\n\n[Image:rId226] The image shows results from an One-Sample Nonparametric Test using ECMiner, indicating that the median value of A1 is significantly different from 0, with a p-value of 0, leading to the rejection of the null hypothesis.",
    "Context_id": "4장_v3_sanitized::chunk_0147",
    "Is_image": true,
    "Image_ids": [
      "rId226"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.9 Nonparametric Test",
      "Result"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Nonparametric Test, with a detailed reference to Independent Samples.\n\nNon-parametric independent samples tests are used to compare two or more groups without assuming a specific distribution. Our software provides the Mann-Whitney U statistic method.",
    "Context_id": "4장_v3_sanitized::chunk_0148",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.9 Nonparametric Test",
      "4.3.9.2 Independent Samples"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Nonparametric Test, with a detailed reference to How to run.\n\n[Analyze] – [Nonparametric Test] - [Independent Samples]\n[image:rId227]\nSelect Analysis Variable, and Group variable. Set the Significance level.\n\n[Image:rId227] This screenshot shows the Nonparametric Test window in ECMiner, used for comparing independent samples without assuming normal distribution. Users can select variables to compare, specify groups, and set significance levels for statistical analysis.",
    "Context_id": "4장_v3_sanitized::chunk_0149",
    "Is_image": true,
    "Image_ids": [
      "rId227"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.9 Nonparametric Test",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Nonparametric Test, with a detailed reference to Result.\n\n[image:rId228]\n\n[Image:rId228] The image shows a nonparametric test result comparing churn status between two groups using Mann-Whitney U Test, indicating a significant difference with p-value < 0.00001, rejecting the null hypothesis that the distributions are identical.",
    "Context_id": "4장_v3_sanitized::chunk_0150",
    "Is_image": true,
    "Image_ids": [
      "rId228"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.9 Nonparametric Test",
      "Result"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Nonparametric Test, with a detailed reference to Paired Samples.\n\nFor non-parametric paired samples, there are two tests, the sign test and Wilcoxon signed-rank test.",
    "Context_id": "4장_v3_sanitized::chunk_0151",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.9 Nonparametric Test",
      "4.3.9.3 Paired Samples"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Nonparametric Test, with a detailed reference to How to run.\n\n[Analyze] – [Nonparametric Test] - [Paired Samples]\n[image:rId229]\nSelect two variables, variable1 and variable2. Set the Significance level.\n\n[Image:rId229]",
    "Context_id": "4장_v3_sanitized::chunk_0152",
    "Is_image": true,
    "Image_ids": [
      "rId229"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.9 Nonparametric Test",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Nonparametric Test, with a detailed reference to Result.\n\n[image:rId230]\n\n[Image:rId230] The image shows results from a nonparametric test comparing two paired samples, A1 and A5, using the Wilcoxon Signed Rank Test. The average values for both samples are provided, along with their standard deviations and significance probabilities. The test concludes that there is a significant difference between the medians of A1",
    "Context_id": "4장_v3_sanitized::chunk_0153",
    "Is_image": true,
    "Image_ids": [
      "rId230"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.9 Nonparametric Test",
      "Result"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Nonparametric Test, with a detailed reference to ANOVA- One-way.\n\nThe Kruskal-Wallis test is a non-parametric method used to compare the medians of three or more independent groups. It’s an alternative to one-way ANOVA for non-normally distributed data.",
    "Context_id": "4장_v3_sanitized::chunk_0154",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.9 Nonparametric Test",
      "4.3.9.4 ANOVA- One-way"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Nonparametric Test, with a detailed reference to How to run.\n\n[Analyze] – [Nonparametric Test] - [ANOVA-One-way]\nResult\n[image:rId232]\n\n[Table:t1305]\n\n[Image:rId231] The image shows an ANOVA (Analysis of Variance) window in ECMiner, a data mining software tool. It is set up for performing a one-way variance analysis with no factors selected yet. The user can choose variables to analyze by checking the boxes next to A1, A5, A6,\n\n[Image:rId232] The image shows a Nonparametric Test (One-way ANOVA) conducted in ECMiner, testing whether the distribution of A1 variable is identical across different groups. The Kruskal-Wallis test indicates no significant difference between the groups, with a p-value of 0.17607.",
    "Context_id": "4장_v3_sanitized::chunk_0155",
    "Is_image": true,
    "Image_ids": [
      "rId232",
      "rId231"
    ],
    "Is_table": true,
    "Table_ids": [
      "t1305"
    ],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.9 Nonparametric Test",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, focusing on Accuracy Measurement.\n\nThe model's accuracy and validity can be measured by comparing the true(original) values with the predicted values.",
    "Context_id": "4장_v3_sanitized::chunk_0156",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.10 Accuracy Measurement"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Accuracy Measurement, with a detailed reference to How to run.\n\n[Classification] or [Regression] from the submenu of [Analyze] – [Accuracy Measurement].",
    "Context_id": "4장_v3_sanitized::chunk_0157",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.10 Accuracy Measurement",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Accuracy Measurement, with a detailed reference to Classification.\n\nEstimation method\n\nThe classification analysis predicts each class label. A confusion matrix is a table used to evaluate the performance of a classification model. Confusion matrix is a 2x2 table with the frequency of true tartet class and predicted class. It shows true positive rate, true negative rate, false positive rate, and false negative rate.\n\nExample\n\n[image:rId233]\n\n[Image:rId233] The image shows the Classification window in ECMiner, where the user is setting up a classification model with \"churn_status\" as the dependent variable, \"LRN1_YHAT\" as the predictor, and observing the results. The goal is to predict customer churn based on historical data.\n\n[image:rId234]\n\n[Image:rId234] The screenshot shows the accuracy measurement results for a classification model using ECMiner, displaying a confusion matrix with classification accuracy, misclassification rate, and frequency per class.",
    "Context_id": "4장_v3_sanitized::chunk_0158",
    "Is_image": true,
    "Image_ids": [
      "rId233",
      "rId234"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.10 Accuracy Measurement",
      "4.3.10.1 Classification"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Accuracy Measurement, with a detailed reference to Regression.\n\nEstimation method\n\nR-square, Mean Absolute Percentage Error (MAPE), Mean Absolute Deviation (MAD), and Mean Squared Deviation (MSD)\n\n(1) R-square\n\nR-square is a statistical measure to evaluate how well a regression model fits the data. It represents the proportion of the variance in the dependent variable. A value closer to 1 indicates better fitting model.\n\n(2) MAPE (Mean Absolute Percentage Error)\n\n[image:rId235] [image:rId236]\n\n[Image:rId235]\n\n[Image:rId236]\n\n(3) MAE (Mean Absolute Error)\n\n[image:rId237] [image:rId238]\n\n[Image:rId237]\n\n[Image:rId238]\n\n(4) RMSE (Root Mean Squared Error)\n\n[image:rId239] [image:rId240]\n\n[Image:rId239]\n\n[Image:rId240]\n\nExample\n\n[image:rId241]\n\n[Image:rId241] The image shows the Statistics window in ECMiner, where the user has selected \"A1\" as the dependent variable and \"PLS2_YHAT1\" as the predictor variable for analysis. This setup is likely used to perform a regression analysis or predictive modeling task within the software.\n\n[image:rId242]\n\n[Image:rId242] The screenshot shows the accuracy measures for a regression analysis using ECMiner, including R Square (0.988212), MAPE (0.091774), MAE (0.100209), and RMSE (0.189231",
    "Context_id": "4장_v3_sanitized::chunk_0159",
    "Is_image": true,
    "Image_ids": [
      "rId235",
      "rId236",
      "rId237",
      "rId238",
      "rId239",
      "rId240",
      "rId241",
      "rId242"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.10 Accuracy Measurement",
      "4.3.10.2 Regression"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, focusing on Gage R&R.\n\nGage R&R (Gage Repeatability and Reproducibility) is a statistical method used to evaluate the amount of variation in a measurement system arising from the measurement device (repeatability) and the people taking the measurements (reproducibility).",
    "Context_id": "4장_v3_sanitized::chunk_0160",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.11 Gage R&R"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Gage R&R, with a detailed reference to Gage Run Chart.\n\nGage Run Chart is a visual tool used to assess the consistency of a measurement system by plotting measurement values based on Part Number, Operator, Measurement Data, and Iteration Count. The chart displays the measurements taken by different operators over several iterations and compares them against a Measurement Average or calculated mean to evaluate the stability and variability of the measurement system over time.\nAn example of the data used is shown below.\n[image:rId243]\n\n[Image:rId243] The image shows a data table in ECMiner, displaying measurement data for different operators and parts over iterations. The columns include operator names, part numbers, iteration counts, and measurement values. This data is likely used for analyzing and optimizing manufacturing processes.",
    "Context_id": "4장_v3_sanitized::chunk_0161",
    "Is_image": true,
    "Image_ids": [
      "rId243"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.11 Gage R&R",
      "4.3.11.1 Gage Run Chart"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Gage R&R, with a detailed reference to How to run.\n\n[Analyze] – [Gage R&R] – [Gage Run Chart]\n[image:rId244]\n\n[Image:rId244] The image is a screenshot of the Gage R&R (Reliability and Reproducibility) module in ECMiner, used for analyzing measurement variability. It allows users to input variables like part number, operator, iteration count, and measurement data to assess gauge reliability. The interface provides options to view results and cancel\n\nPart Number: Select the parts (Must be discrete)\n\nOperator: Select the one who takes measures (Must be discrete)\n\nMeasurement Data: Select the measured data (Must be continuous)\n\nIteration Count (Optional): Repeated measure count for the same part by the same operator. (Must be continuous)\n\nMeasurement Average (Optional): Enter a Measurement Average to compare the part’s measurements. By default, calculated mean of all measurements is shown.\n\nResults\nExample using 3 operators, 10 types of parts, and 3 repetitions.\n[image:rId245]\n\n[Image:rId245] The Gage Run-Chart in ECMiner software displays measurement data for five parts, with three operators (A, B, C) performing measurements. Each operator's data is color-coded: yellow for Operator A, orange for Operator B, and red for Operator C. The chart helps assess the consistency and reliability of",
    "Context_id": "4장_v3_sanitized::chunk_0162",
    "Is_image": true,
    "Image_ids": [
      "rId244",
      "rId245"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.11 Gage R&R",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Gage R&R, with a detailed reference to Gage Linearity and Bias Study.\n\nGage Linearity and Bias Study evaluates the accuracy and consistency of the measurement system using various Part Number, their Standard Value, and Measurement Data. The difference between the measured values and the standard values identifies as the bias, while considering Process Variation to analyze whether linearity is maintained across the full measurement range.\nAn example of the data used is shown below.\n[image:rId246]\nHow to run\n[Analyze] – [Gage R&R] – [Gage Linearity and Bias Study]\n[image:rId247]\n\n[Image:rId246] The image shows an Excel-like interface with a table displaying data related to operators, part numbers, iteration counts, measurement data, and standard values. The data appears to be organized for analysis, likely in a quality control or manufacturing context.\n\n[Image:rId247] The image is a screenshot of the Gage R&R (Reliability and Reproducibility) module in ECMiner, used for analyzing measurement variability in manufacturing processes. It allows users to input variables like operator, part number, iteration count, and measurement data, with options to specify standard values and process variation.\n\nPart Number: Select the parts. (Must be discrete)\n\nStandard Value: Select the standard value of the measurement (Must be continuous)\n\nMeasurement Data: Select the measured data (Must be Continuous)\n\nProcess Variation: Enter the process standard deviation which represents the study variation value from a Gage R&R study or 6 * standard deviation.\n\nResults\n[image:rId248]\nThe chart on the left shows the linear relationship between bias and the data, and the table on the right provides values related to linearity and bias.\n\n[Image:rId248] The Gage Linearity and Bias Study in ECMiner software evaluates measurement system accuracy by plotting bias against reference values, showing linear regression, UCI/LCI limits, and statistical parameters like slope and R-squared.",
    "Context_id": "4장_v3_sanitized::chunk_0163",
    "Is_image": true,
    "Image_ids": [
      "rId246",
      "rId247",
      "rId248"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.11 Gage R&R",
      "4.3.11.2 Gage Linearity and Bias Study"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Gage R&R, with a detailed reference to Gage R&R Study (Crossed Design).\n\nIn a crossed design, every operator measures every part multiple times. It determines suitability of the measurement system. There are two methods: Variance Analysis and X -bar and R methods. If the user wants to analyze the interaction between operators and parts, a crossed design is preferable.\nHow to run\n[Analyze] – [Gage R&R] – [Gage R&R Study (Crossed Design)]\n[image:rId249]\n\n[Image:rId249] The image is a screenshot of the Gage R&R (Reliability and Reproducibility) analysis window in ECMiner, a data mining software. It allows users to select measurement data for gauges, including variables like operator, part number, iteration count, and measurement data. The user can choose between Vari\n\nPart Number: Select the parts (Must be discrete)\n\nOperator: Select the one who takes measures (Must be discrete)\n\nMeasurement Data: Select the measured data (Must be continuous)\n\nAnalysis Method: Choose either Variance analysis or X-bar and R method.\n\n[image:rId250]\n\n[Image:rId250] The Gage R&R Study Options window in ECMiner is used to configure settings for a Reliability and Reproducibility study, including setting the Study Variation multiplier to 6, Process Tolerance, and Standard Deviation values. The OK button confirms changes, while Cancel exits without saving.\n\nStudy Variation: Enter the coefficient to obtain the Study Variation.\n\nProcess Tolerance: Enter an empirically known tolerance to calculate %tolerance.\n\nStandard Deviation: Enter an empirically known Historical Standard to calculate %process.\n\nResults\n\nGeneral Information\n\nShows the results of ANOVA (only when variance analysis is selected) and Gage R&R analysis results.\n\n[image:rId251]\n\n[Image:rId251] The image is a screenshot of an ANOVA table from ECMiner, showing results for a Gage R&R study. It analyzes the variability in measurements due to different factors such as parts, operators, and interactions between them. The table provides statistical measures like degrees of freedom (DF), sum of squares (SS\n\nR Control Chart by Operator:\n\nEach point displays the difference in the smallest and the biggest measurement of the same part by each operator.\n\n[image:rId252]\n\n[Image:rId252] The Gage R&R Study screen in ECMiner displays a control chart comparing the range of observations across three operators (A, B, C) for a specific measurement process. The chart shows that Operator A has the highest variability, with UCL (Upper Control Limit) at 2.74560\n\nX -Bar Control Chart by Operator\n\nEach point displays the average measurement of the same part by each operator.\n\n[image:rId253]\n\n[Image:rId253] The Gage R&R Study screen in ECMiner displays an XBar control chart comparing three operators' measurements, showing variability and consistency across different operators.\n\nOperator*Parts Interaction:\n\nDisplays How different operators interact with various parts during the measurement process.\n\n[image:rId254]\n\n[Image:rId254] The Gage R&R Study screen in ECMiner displays a control chart comparing mean observations across different operators (A, B, C) for parts 1 to 10. It shows variability in measurements among operators, indicating potential issues with consistency and reliability in part measurement.\n\nObservations per Operator\n\nDisplays box plots of all measurements for each operator, with the solid line representing the mean.\n\n[image:rId255]\n\n[Image:rId255] This screenshot shows an R&R (Reliability, Reproducibility, and Repeatability) study using ECMiner software, comparing observations across three operators (A, B, C). The chart illustrates the variability in measurements made by each operator, with Operator A having the highest variability, followed by Operator B\n\nObservations by Part:\n\nDisplays observations per part only, with the solid line representing the mean.\n\n[image:rId256]\n\n[Image:rId256] The Gage R&R Study screen in ECMiner displays a plot comparing average observations by part (pink line) with observations by part (blue squares). It assesses measurement variability across different parts, operators, and interactions, aiding in quality control and process improvement.\n\nComponents of Variability\n\nDisplays where the variation in observed values originates.\n\n[image:rId257]\n\n[Image:rId257] The Gage R&R Study screen in ECMiner data mining software displays a bar graph comparing \"Contribution\" (red bars) and \"Research Variability\" (green bars) across different categories such as Gage R&R, Iteration, Reproducibility, and Parts to parts. The graph helps analyze",
    "Context_id": "4장_v3_sanitized::chunk_0164",
    "Is_image": true,
    "Image_ids": [
      "rId249",
      "rId250",
      "rId251",
      "rId252",
      "rId253",
      "rId254",
      "rId255",
      "rId256",
      "rId257"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.11 Gage R&R",
      "4.3.11.3 Gage R&R Study (Crossed Design)"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Analy ze, under the subsection Gage R&R, with a detailed reference to Gage R&R Study (Nested Design).\n\nGage R&R Study (Nested Design) is a technique which each part is measured by only one operator. It is commonly used in destructive testing and in systems where once one operator measures a part, no other operator can measure the same part. It is essential to assume that parts within each batch are nearly identical. If this assumption is violated, operators will measure different parts, making it unclear whether the variation is due to part differences or issues in the measurement system. In nested designs, total variation is divided into part-to-part, reproducibility, and repeatability, allowing for accurate identification of measurement variability sources.\nHow to run\n[Analyze] – [Gage R&R] – [Gage R&R Study (Nested Design)]\n[image:rId258]\n\n[Image:rId258] The image is a screenshot of the Gage R&R (Reliability and Reproducibility) module in ECMiner, used for analyzing measurement data to assess the reliability and reproducibility of gauges. It displays fields for selecting measurement data variables like Part Number, Operator, Iteration Count, and Measurement Data\n\nPart Number: Select the parts (Must be discrete)\n\nOperator: Select the one who takes measures (Must be discrete)\n\nMeasurement Data: Select the measured data (Must be continuous)\n\n[image:rId259]\n\n[Image:rId259] The Gage R&R Study Options window in ECMiner is used to configure settings for a Reliability and Reproducibility study, including setting the Study Variation multiplier, Process Tolerance, and Standard Deviation values.\n\nStudy Variation: Enter the coefficient to obtain the Study Variation.\n\nProcess Tolerance: Enter an empirically known tolerance to calculate %tolerance.\n\nStandard Deviation: Enter an empirically known Historical Standard to calculate %process.\n\nResults\n\nGeneral Information\n\nShows the results of ANOVA and Gage R&R analysis results.\n\n[image:rId260]\n\n[Image:rId260] This screenshot shows an ANOVA table for a Gage R&R study in ECMiner, analyzing variation in measurements across parts, operators, and iterations. The table indicates that part-to-part variability is the primary source of variation, with a significant F-value suggesting it's statistically significant.\n\nR Control Chart by Operator\n\nEach point displays the difference in the smallest and the biggest measurement of the same part by each operator.\n\n[image:rId261]\n\n[Image:rId261] The Gage R&R Study screen in ECMiner displays a control chart comparing the range of observations across three operators (1, 2, and 3) over 15 parts. The UCL and LCL values indicate the upper and lower control limits for variation, with Operator 1 showing significant variability compared\n\nX -Bar Control Chart by Operato r\n\nEach point displays the average measurement of the same part by each operator.\n\n[image:rId262]\n\n[Image:rId262] The Gage R&R Study screen in ECMiner displays an XBar control chart comparing three operators' observations, showing variability and consistency across different parts. The chart highlights differences between operators and provides UCL and LCL for quality control analysis.\n\nObservations per Operator\n\nDisplays box plots of all measurements for each operator, with the solid line representing the mean.\n\n[image:rId263]\n\n[Image:rId263] The Gage R&R Study screen in ECMiner displays a box plot comparing observations across three operators, highlighting variability and consistency in measurements.\n\nObservations by Part\n\nDisplays observations per part only, with the solid line representing the mean.\n\n[image:rId264]\n\n[Image:rId264] The Gage R&R Study screen in ECMiner displays a control chart comparing average observations by part to observations by part, illustrating variability across different parts and operators.\n\nComponents of Variability\n\nDisplays where the variation in observed values originates.\n\n[image:rId265]\n\n[Image:rId265] The Gage R&R Study screen in ECMiner shows a bar chart comparing Contribution (red) and Research Variability (green) across different categories: Gage R&R, Iteration, Reproducibility, and Parts to parts. The chart indicates that Research Variability is consistently higher than Contribution, suggesting significant",
    "Context_id": "4장_v3_sanitized::chunk_0165",
    "Is_image": true,
    "Image_ids": [
      "rId258",
      "rId259",
      "rId260",
      "rId261",
      "rId262",
      "rId263",
      "rId264",
      "rId265"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.3 Analy ze",
      "4.3.11 Gage R&R",
      "4.3.11.4 Gage R&R Study (Nested Design)"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Chart.\n\nData Browser provides various charting functions.",
    "Context_id": "4장_v3_sanitized::chunk_0166",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.4 Chart"
    ],
    "Section_length": 2,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Chart, focusing on Basic Charts.\n\n[image:rId266]\n2D chart, 3D chart, Bar chart, Box chart, Matrix chart, Pareto chart, Pie chart and Multi-chart functions.\n\n[Image:rId266] The image shows a menu in ECMiner data mining software, displaying various chart types such as 2D, 3D, Bar, Box, Matrix, Pareto, Pie, and Multi-Chart options for visualizing data.",
    "Context_id": "4장_v3_sanitized::chunk_0167",
    "Is_image": true,
    "Image_ids": [
      "rId266"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.4 Chart",
      "Basic Charts"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Chart, focusing on Basic Charts.",
    "Context_id": "4장_v3_sanitized::chunk_0168",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.4 Chart",
      "4.4.1 Basic Charts"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Chart, under the subsection Basic Charts, with a detailed reference to How to run.\n\n[Chart]",
    "Context_id": "4장_v3_sanitized::chunk_0169",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.4 Chart",
      "4.4.1 Basic Charts",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Chart, under the subsection Basic Charts, with a detailed reference to How to choose chart options.\n\nThe following example is a two-dimensional chart.\n[image:rId267]\n1: Add/delete. Add more chart or delete chart.\n2: Select variables for chart\n3: You may select a variable field in data browser instead selecting a variable.\n\n[Image:rId267] The image shows the \"Chart\" settings in ECMiner, where users can add or delete series for a 2D chart, adjust the X and Y axes, and confirm or cancel changes.",
    "Context_id": "4장_v3_sanitized::chunk_0170",
    "Is_image": true,
    "Image_ids": [
      "rId267"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.4 Chart",
      "4.4.1 Basic Charts",
      "How to choose chart options"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Chart, under the subsection Basic Charts, with a detailed reference to Results.\n\n2D chart\n\n[image:rId268]\n\n[Image:rId268] The image shows an A7 vs Series1 scatter plot in ECMiner, displaying data points over time. The x-axis represents Data Index, while the y-axis shows A7 values. The plot illustrates how A7 changes over time, with Series1 possibly representing another metric for comparison.\n\nPie chart\n\n[image:rId269]\n\n[Image:rId269] The pie chart in ECMiner displays the distribution of different categories labeled A to G, with each slice representing a percentage of the total data. The largest segment is G, followed by C, B, and K, while smaller segments include J, I, H, E, D, and F. This visualization helps",
    "Context_id": "4장_v3_sanitized::chunk_0171",
    "Is_image": true,
    "Image_ids": [
      "rId268",
      "rId269"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.4 Chart",
      "4.4.1 Basic Charts",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Chart, focusing on Multi chart.\n\nMulti-chart is an unique chart of ECMiner™ which makes it easy to see the characteristics of multiple variables.",
    "Context_id": "4장_v3_sanitized::chunk_0172",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.4 Chart",
      "4.4.2 Multi chart"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Chart, under the subsection Multi chart, with a detailed reference to How to run.\n\n[Analyze] – [Chart] - [Multi-chart]\n[image:rId270]\n\n[Image:rId270] The image shows the \"customer_churn\" window in ECMiner, a data mining software tool. It is used to analyze customer churn data by selecting a trend chart type, setting axis labels, and configuring control limits for monitoring data trends over time. The user can also choose to display points or lines on the chart",
    "Context_id": "4장_v3_sanitized::chunk_0173",
    "Is_image": true,
    "Image_ids": [
      "rId270"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.4 Chart",
      "4.4.2 Multi chart",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Chart, under the subsection Multi chart, with a detailed reference to Chart.\n\nChart Type\n\nTrend, Data, Box Plot, Distribution, and Correlation charts.\n\nData: Displays data as a scatter plot.\n\nBox Plot: Visualizes data distribution.\n\nDistribution: Shows normal distribution of variables.\n\nCorrelation: Highlights relationships between variables.\n\nSplit Chart:\n\nSelect a group variable. Items with the same variable value (e.g., 1 or -1) are drawn separately.\n\nGroup Variable:\n\nSelect a group variable. Items with the same value are shown as dots of the same color.\n\nX Axis\n\nLabel: Select a discrete variable as the X-axis in the chart.\n\nOrder: This is a variable that determines in what order the variables in the label will be displayed on the X-axis.\n\nY Axis\n\nY1: Select a variable on the left Y-axis. Multiple Y-axis selections are possible.\n\nY2: Select a variable on the right Y-axis.\n\nX, Y: Select Correlation as the chart type, decide which variable to use as the X-axis and which variable to use as the Y-axis.",
    "Context_id": "4장_v3_sanitized::chunk_0174",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.4 Chart",
      "4.4.2 Multi chart",
      "Chart"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Chart, under the subsection Multi chart, with a detailed reference to Check Box Options.\n\nRegression Analysis\n\nOptions for regression function.\n\nDisplay as Points/Lines\n\nOptions in the plot for connecting points with lines.\n\nBasic Statistics\n\nOptions for descriptive statistics with Median, Standard Deviation, Average, Maximum, Minimum, and Range.\n\nOutlier\n\nOptions for displaying outliers.\n\nThe following is the Box Chart screen when ‘Basic Statistics’ and ‘Outliers’ are selected.\n\n[image:rId271]\n\n[Image:rId271] The image shows a box plot analysis using ECMiner software, displaying four variables (A1, A5, A6, A7) categorized by two groups (0 and 1). The goal is to visualize the distribution of these variables across different categories, identifying any outliers or patterns in the data.\n\nOther Options\n\nOutput Option (Row): Set how many charts to show horizontally.\n\nOutput Option (Column): Set how many charts to show vertically.\n\nControl limit: Options for the basis for displaying the control line.",
    "Context_id": "4장_v3_sanitized::chunk_0175",
    "Is_image": true,
    "Image_ids": [
      "rId271"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.4 Chart",
      "4.4.2 Multi chart",
      "Check Box Options"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Chart, under the subsection Multi chart, with a detailed reference to Example.\n\nTrend chart type.\n\n[image:rId272]\n\n[Image:rId272] The image shows a screenshot of the ECMiner data mining software, displaying time series data for temperature (temp) and humidity (humid) over a period from January to June 2020. The software is used for analyzing trends and patterns in the data, with options for control limits and output settings.\n\nBox plot chart type.\n\n[image:rId271]\n\nDistribution chart type.\n\n[image:rId273]\n\n[Image:rId273] The image shows a screenshot of the ECMiner data mining software, specifically the \"series_data\" window. It displays four line charts representing different variables: temp, humid, GHI, and ei. The X-axis represents values ranging from -12 to 46, while the Y-axis shows corresponding data points\n\nCorrelation chart type.\n\n[image:rId274]\n\n[Image:rId274] The image shows the ECMiner software's correlation analysis feature, displaying scatter plots for variables A14 vs A15 and A14 vs A19. The user is configuring these charts to analyze the relationship between the selected variables, with options for control limits and output settings.",
    "Context_id": "4장_v3_sanitized::chunk_0176",
    "Is_image": true,
    "Image_ids": [
      "rId272",
      "rId271",
      "rId273",
      "rId274"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.4 Chart",
      "4.4.2 Multi chart",
      "Example"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Data.",
    "Context_id": "4장_v3_sanitized::chunk_0177",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.5 Data"
    ],
    "Section_length": 2,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Data, focusing on Data Sorting.\n\nThe Data Browser supports multiple column sorting. This function works the same as the Sort Node in the Preprocessing Nodes.",
    "Context_id": "4장_v3_sanitized::chunk_0178",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.5 Data",
      "4.5.1 Data Sorting"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Data, under the subsection Data Sorting, with a detailed reference to How to run.\n\n[Data] - [Sort]\nSort the data in ascending or descending order by clicking the direction icon. To sort by multiple fields, select additional fields for multi-level sorting.\n[image:rId275]\n\n[Image:rId275] The image shows a screenshot of the ECMiner data mining software, specifically focusing on a customer churn analysis. The user is sorting data by columns A2 and A3 to identify patterns in customer behavior related to churn. The goal is to analyze which factors contribute most significantly to customer attrition.",
    "Context_id": "4장_v3_sanitized::chunk_0179",
    "Is_image": true,
    "Image_ids": [
      "rId275"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.5 Data",
      "4.5.1 Data Sorting",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Data, focusing on Derived Variables.\n\nThe Data Browser supports creating derived variables. This function works the same as the Derived Column Node in the Preprocessing Nodes.",
    "Context_id": "4장_v3_sanitized::chunk_0180",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.5 Data",
      "4.5.2 Derived Variables"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Data, under the subsection Derived Variables, with a detailed reference to How to run.\n\n[Data] - [Derived Variables]\n[image:rId276]\n\n[Image:rId276] The image shows the \"Derived Variable\" dialog box in ECMiner, where users can add or delete derived variables for analysis. The user has selected \"Derived 1\" as the new variable name.\n\n(1) Management of derived variables\n\nAdd for creating a new derived variable\n\nDelete for removing a derived variable\n\nIf only one list remains, pressing the delete button will not remove it.\n\n(2) Name of a derived variable\n\nGive a name of the derived variable\n\n(3) Expression Editor\n\nUse the expression editor to define how to calculate the derived variable\n\n[image:rId277]\n\n[Image:rId277] The image shows a screenshot of the ECMiner data mining software, specifically focusing on a customer churn analysis. The user is in the process of creating a derived variable by adding columns A7 and A5 together. This operation is likely part of a data preprocessing step to identify patterns or relationships between variables that could influence customer",
    "Context_id": "4장_v3_sanitized::chunk_0181",
    "Is_image": true,
    "Image_ids": [
      "rId276",
      "rId277"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.5 Data",
      "4.5.2 Derived Variables",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Data, under the subsection Derived Variables, with a detailed reference to Results.",
    "Context_id": "4장_v3_sanitized::chunk_0182",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.5 Data",
      "4.5.2 Derived Variables",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Data, under the subsection Derived Variables, with a detailed reference to [image:rId278].\n\n[Image:rId278] The image shows a customer churn analysis in ECMiner, displaying customer IDs, attributes, and churn status. The data is organized in a table format with columns for customer ID, attributes A5 to A9, and churn status. The highlighted row indicates a customer with an ID of 394,39",
    "Context_id": "4장_v3_sanitized::chunk_0183",
    "Is_image": true,
    "Image_ids": [
      "rId278"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.5 Data",
      "4.5.2 Derived Variables",
      "[image:rId278]"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Data, focusing on Apply.\n\nThe Data Browser supports creation of streams onto the Workspace. The preprocessing functions that are applied in the Data Browser can be created into a stream with the Apply function.",
    "Context_id": "4장_v3_sanitized::chunk_0184",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.5 Data",
      "4.5.3 Apply"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Data, under the subsection Apply, with a detailed reference to How to run.\n\n[Data] - [Apply]",
    "Context_id": "4장_v3_sanitized::chunk_0185",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.5 Data",
      "4.5.3 Apply",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Data, under the subsection Apply, with a detailed reference to Results.\n\n[image:rId279]\n\n[Image:rId279] The image illustrates a data processing pipeline in ECMiner, showing steps like loading data, filtering columns, selecting rows, deriving new columns, and changing data types. This sequence is used to prepare data for analysis.\n\nExamples\n\nDelete column\n\n[image:rId280]\n\n[Image:rId280] The image shows the \"customer churn\" dataset in ECMiner, a data mining software tool. It displays customer information with columns for age, gender, marital status, and churn status. The highlighted area indicates options to delete columns, copy data, select all rows, and send data to Excel. This screen is used\n\nPress right click on the column that you want to delete and click ‘Delete Column’ in the Data Browser. Then run the Apply function to create a stream that applies the preprocessing methods. In the Workspace, the File Reader Node is automatically connected to the Column Filter Node that deletes the selected column.\n\n[image:rId281] [image:rId282]\n\n[Image:rId281] The image shows the \"LOAD\" button in ECMiner, which is used to import customer churn data into the software for analysis. The \"Column Filter\" option allows users to specify which columns should be included in the analysis process. This setup facilitates data preparation and filtering before conducting mining operations.\n\n[Image:rId282] The image shows the Node Property window in ECMiner, where users can manage node properties such as name, description, and variable filters for data analysis. The highlighted section displays a list of variables with their corresponding names and filters, indicating that the user is likely working on a data mining project involving churn status analysis.\n\nDelete row\n\n[image:rId283]\n\n[Image:rId283] The image shows a data mining software interface with a customer churn analysis, displaying various columns like age, gender, and churn status. The user is interacting with the software to analyze customer data, specifically focusing on deleting rows for further analysis.\n\nPress right click on the row that you want to delete and click ‘Delete Row’ in the Data Browser. Then run the Apply function to create a stream that applies the preprocessing methods. In the Workspace, the File Reader Node is automatically connected to the Row Select Node that deletes the selected column.\n\n[image:rId284] [image:rId285]\n\n[Image:rId284] The image shows the ECMiner software interface, specifically the \"Load\" function for importing customer churn data into the system, with a focus on selecting specific rows for analysis.\n\n[Image:rId285] The image shows the Node Property window in ECMiner, where the user can configure selection options for a node named \"Row Select.\" The condition is set to \"(@ROWNUM <> 3),\" indicating that only rows with a row number not equal to 3 will be selected.\n\nNOTE (@ROWNUM <> 3) is a conditional statement that means \"a row whose row index is not 3\".\n\nDerived Variables\n\n[image:rId278]\n\nAfter the Derived Variable function in the Data Browser is applied, run the Apply function to create a stream. In the Workspace, the File Reader Node is automatically connected to the Derived Column Node that creates a new variable with the defined conditional statement.\n\n[image:rId286] [image:rId287]\n\n[Image:rId287] The image shows the Node Property window in ECMiner, where a derived column named \"Derived Column\" is being edited. The user can add, remove, or edit derived variables to create new columns based on existing data.\n\n[Image:rId286] The image shows the process of loading customer churn data into a derived column in ECMiner, which is used for data mining and analysis to identify patterns and predict churn.\n\nNOTE ({A1} + {A6}) is a conditional statement that means \"add the values of A1 and A6 variables\".\n\nSort\n\n[image:rId275]\n\nAfter the Sort function in the Data Browser is applied, run the Apply function to create a stream. In the Workspace, the File Reader Node is automatically connected to the Align Node that sorts the sele ct ed variable.\n\n[image:rId288] [image:rId289]\n\n[Image:rId289] The image shows the \"Node Property\" window in ECMiner, where users can sort variables by name and direction. The current sorting is set to \"Ascend,\" indicating that the variables A2 and A3 will be sorted alphabetically in ascending order. This feature helps in organizing and analyzing data efficiently within the software\n\n[Image:rId288] The image shows the ECMiner software interface, where the user is loading customer churn data for sorting purposes. The process involves uploading the dataset to analyze customer behavior patterns related to churn.\n\nApply multiple preprocessing\n\nPreprocessing results can be applied one by one as in the example above, but multiple preprocessing results can also be applied at once.\n\nBelow is an example of the created stream after applying multiple preprocessing\n\n[image:rId290]\n\n[Image:rId290] The image shows a data flow diagram in ECMiner, illustrating the process of loading customer churn data, applying column filters, selecting rows, deriving columns, and aligning them for analysis.",
    "Context_id": "4장_v3_sanitized::chunk_0186",
    "Is_image": true,
    "Image_ids": [
      "rId279",
      "rId280",
      "rId281",
      "rId282",
      "rId283",
      "rId284",
      "rId285",
      "rId278",
      "rId286",
      "rId287",
      "rId275",
      "rId288",
      "rId289",
      "rId290"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.5 Data",
      "4.5.3 Apply",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Data, focusing on Filter.\n\nThe Data Browser supports Filtering. This function works similar to the Derived Column Node in the Preprocessing Nodes, but in the data browser the filter function applies to all variables.",
    "Context_id": "4장_v3_sanitized::chunk_0187",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.5 Data",
      "4.5.4 Filter"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Data, under the subsection Filter, with a detailed reference to How to run.\n\n[Data] – [Filter]\n[image:rId291]\n\n[Image:rId291] The Variable Filter Dialog Window in ECMiner is used to filter variables based on conditions, allowing users to specify statistical criteria for inclusion or exclusion. It includes options to add or delete items, select conditions, choose comparisons, and view statistics. The interface facilitates data preprocessing for mining tasks by enabling users to refine their analysis with\n\n1. \"Add\" to add a condition. \"Delete\" to remove the last one\n\n2. Select statistical conditions, such as standard deviation.\n\n3. Choose comparison operators >, =, <, etc.\n\n4. Specify the value for comparison.",
    "Context_id": "4장_v3_sanitized::chunk_0188",
    "Is_image": true,
    "Image_ids": [
      "rId291"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.5 Data",
      "4.5.4 Filter",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Data, focusing on Freeze Columns.\n\nThe more data columns you have, the more likely you’ll need to scroll horizontally to view variables. When comparing distant columns, it’s difficult to do so visually. With 'Freeze Coumns,' the specified column is pinned, allowing the remaining columns to be visible when scrolling.",
    "Context_id": "4장_v3_sanitized::chunk_0189",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.5 Data",
      "4.5.5 Freeze Columns"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Data, under the subsection Freeze Columns, with a detailed reference to How to run.\n\n[Data] - [Freeze Columns]\n[image:rId292]\nNumber of Columns: Select how many columns to freeze from the first column.\n\n[Image:rId292] The Freeze Column dialog in ECMiner allows users to freeze one column, preventing it from scrolling while other columns remain visible for easy reference. This feature is useful for maintaining a consistent view of specific data points during analysis.",
    "Context_id": "4장_v3_sanitized::chunk_0190",
    "Is_image": true,
    "Image_ids": [
      "rId292"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.5 Data",
      "4.5.5 Freeze Columns",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Data, under the subsection Freeze Columns, with a detailed reference to Results.\n\nIf you freeze 1 column, you can see that the first columns ‘A1’ is fixed to the left even when you move the horizontal scroll bar to the right.\n[image:rId293]\n\n[Image:rId293] The image shows an Excel spreadsheet named \"customer_churn\" with customer data, including churn status, and various attributes like age, income, and other factors. The main purpose is to analyze customer churn patterns using data mining techniques.",
    "Context_id": "4장_v3_sanitized::chunk_0191",
    "Is_image": true,
    "Image_ids": [
      "rId293"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.5 Data",
      "4.5.5 Freeze Columns",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Data, focusing on Box-Cox Transformation.\n\nTo apply a control chart, the data must follow a normal distribution, which is often not the case. The Box-Cox Transformation provides a method to convert non-normal data into a normal distribution.",
    "Context_id": "4장_v3_sanitized::chunk_0192",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.5 Data",
      "4.5.6 Box-Cox Transformation"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Data, under the subsection Box-Cox Transformation, with a detailed reference to How to run.\n\n[Data] – [Box-Cox Transformation]\n[image:rId294]\n\n[Image:rId294] The image shows the \"Box-Cox Transformation\" window in ECMiner, where the user is selecting the target variable A1 for applying a Box-Cox transformation to analyze data.",
    "Context_id": "4장_v3_sanitized::chunk_0193",
    "Is_image": true,
    "Image_ids": [
      "rId294"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.5 Data",
      "4.5.6 Box-Cox Transformation",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Data, under the subsection Box-Cox Transformation, with a detailed reference to Results.\n\nIt provides the estimated lambda to define the transformation formula and offers normality test statistics before and after transformation, showing the improvement in normality. The conversion formula can be applied for a new variable using the Derived Variable Node.\n[image:rId295]\n\n[Image:rId295] The image shows the results of applying Box-Cox transformation to data in ECMiner, with a maximum likelihood value of -20990.2661 and an estimated lambda of 0.03. The transformed equation is Wi = (POWER(A1, 0.0) -\n\nNormal Probability Plot (before transformation)\n\nThis graph shows how closely the data follows a normal distribution before transformation. If a lot of data is distributed around the red line, the data can be said to follow normality. The more it deviates from the red line, the more it violates the assumption of normality.\n\n[image:rId296]\n\n[Image:rId296] The image shows a Box-Cox Transformation analysis in ECMiner, where the Normal Probability Plot before transformation indicates non-normality, while the plot after transformation aligns more closely with a normal distribution, suggesting successful transformation for statistical analysis.\n\nNormal Probability Plot (after Transformation)\n\nThis graph shows how well the data transformed by the estimated transformation formula follows the normal distribution. If a lot of data is distributed around the red line, the data can be said to follow normality. The more it deviates from the red line, the more it violates the assumption of normality.\n\n[image:rId297]\n\n[Image:rId297] The image shows the Box-Cox Transformation process in ECMiner, where the normal distribution after transformation is plotted against the transformed values. The plot indicates that the data has been successfully transformed to achieve a more normal distribution, as evidenced by the points closely following the red line representing the ideal normal distribution.\n\nLambda Estimation\n\nThe transformation formula is determined using the lambda with the maximum likelihood as an estimate, and a graph showing the change in likelihood depending on the lambda is provided.\n\n[image:rId298]\n\n[Image:rId298] The image shows the Lambda estimation process in ECMiner, where the Box-Cox Transformation is applied to data. The graph plots the likelihood against different values of lambda, indicating how well the transformed data fits a normal distribution. The goal is to find the optimal lambda value that maximizes the likelihood, improving the model's",
    "Context_id": "4장_v3_sanitized::chunk_0194",
    "Is_image": true,
    "Image_ids": [
      "rId295",
      "rId296",
      "rId297",
      "rId298"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.5 Data",
      "4.5.6 Box-Cox Transformation",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Data, focusing on Johnson Transformation.\n\nThe Johnson Transformation offers a formula to convert non-normal data into a normal distribution, allowing it to be used in control charts.",
    "Context_id": "4장_v3_sanitized::chunk_0195",
    "Is_image": false,
    "Image_ids": [],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.5 Data",
      "4.5.7 Johnson Transformation"
    ],
    "Section_length": 3,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Data, under the subsection Johnson Transformation, with a detailed reference to How to run.\n\n[Data] – [Johnson Transformation]\n[image:rId299]\n\n[Image:rId299] The Johnson Transformation dialog in ECMiner is used to transform a target variable A1 with a standard P-value of 0.05, likely for statistical analysis or data preprocessing.",
    "Context_id": "4장_v3_sanitized::chunk_0196",
    "Is_image": true,
    "Image_ids": [
      "rId299"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.5 Data",
      "4.5.7 Johnson Transformation",
      "How to run"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  },
  {
    "Context": "This content is about the section Data Browser, and more specifically it belongs to Data, under the subsection Johnson Transformation, with a detailed reference to Results.\n\nOptimal Transformation Function\n\nProvides the estimated transformation function that best fits a normal distribution. This function can be applied as a transformed variable using the Derived Variable Node.\n\nNormality Test\n\nAnderson-Darling statistic and p-value to evaluate how the variable follows a normal distribution. A p-value greater than 0.05 indicates normality.\n\n[image:rId300]\n\n[Image:rId300] The Johnson Transformation screen in ECMiner shows that A1 has an optimal Z-value of 0.71, with a p-value of 0. The transformation function is SB = 1.1425 + 1.0674 * log(({A1} - 8.6\n\nNormal Probability Plot (before trans f ormation)\n\nThis graph shows how closely the data follows a normal distribution before transformation. If a lot of data is distributed around the red line, the data can be said to follow normality. The more it deviates from the red line, the more it violates the assumption of normality.\n\n[image:rId301]\n\n[Image:rId301] The image shows the Johnson Transformation process in ECMiner, where the Normal Distribution of A1 is plotted before and after transformation. The plot demonstrates that the transformed data follows a straight line, indicating normality, which is essential for statistical analysis.\n\nNormal Probability Plot (after transformation)\n\nThis graph shows how the transformed data follows the normal distribution. The more it deviates from the red line, the more it violates the assumption of normality.\n\n[image:rId302]\n\n[Image:rId302] The image shows the Johnson Transformation process in ECMiner, where the normal distribution after transformation is plotted against the transformed values. The plot indicates that the data has been successfully transformed to achieve a more normal distribution, as evidenced by the straight line on the graph.\n\nTransformation Estimat e\n\nProvides a graph that allows you to understand the extent to which transformation data that varies depending on the Z value follows a normal distribution (p-value). The larger the p-value, the more it can be said to satisfy normal distribution.\n\n[image:rId303]\n\n[Image:rId303] The Johnson Transformation window in ECMiner shows the transformation estimate, z-value of the maximum p-value, and reference P values for a normal probability plot before and after transformation. The red bars represent the transformation estimate, while the blue line indicates the z-value of the maximum p-value.",
    "Context_id": "4장_v3_sanitized::chunk_0197",
    "Is_image": true,
    "Image_ids": [
      "rId300",
      "rId301",
      "rId302",
      "rId303"
    ],
    "Is_table": false,
    "Table_ids": [],
    "Section_path": [
      "Chapter 4 Data Browser",
      "4.5 Data",
      "4.5.7 Johnson Transformation",
      "Results"
    ],
    "Section_length": 4,
    "Page_number": null,
    "File_name": "4장_v3_sanitized.json"
  }
]